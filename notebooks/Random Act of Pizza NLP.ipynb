{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project hypotheses\n",
    "\n",
    "## Localization\n",
    "\n",
    "Current data come from a supposedly wide audience, since Reddit is a well-known tool in the US.\n",
    "The first hypothesis states that Reddit utilisation doesn't apply a strong input filtering of the relevant population, thus biasing the dataset towards a subpopulation.\n",
    "Second hypothesis is that business context and targeted population are sufficiently similar to the dataset population, even if the location is different, such as in France where Reddit has less coverage.\n",
    "\n",
    "## Time shift\n",
    "\n",
    "Even if at current state (2022/12/26), r/RAOP rules have strong emphasis on the relative legitimacy (reddit account metadata) of applicants to avoid inappropriate requests, they cannot be taken into account here.\n",
    "Indeed, they may have evolved over time, which already adds bias to the historical data, but obviously cannot be applied retrospectively now, 9 years later.\n",
    "Nonetheless, we assume that altruism is a time constant through a wide population.\n",
    "World-wide economic situation shift over time is also neglected since our business object is a vital food product, ðŸš€ popular, and still affordable.\n",
    "\n",
    "## Wisdom of crowds\n",
    "\n",
    "Even if we disregard the rules process, Reddit structure (comments, votes, account metadata) is assimilated to an influence soft-voting tool.\n",
    "That's why it's assumed that donation process and request legitimacy are not misplaced, and we're confident about the transfert between RAOP donation purpose and our business objective.\n",
    "So if a request led to a donation, thus the request was legitimate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Business context\n",
    "\n",
    "## Marketing campaign\n",
    "\n",
    "I'm running a pizza restaurant at a fast-growing pace with some few localizations.\n",
    "In order to promote our upcoming additional location, we're launching a marketing campaign to donate some pizza to people who made a request.\n",
    "It can leverage some pain points:\n",
    "+ Expand our brand image\n",
    "+ Minimize unsells waste\n",
    "+ Donate to people in need\n",
    "\n",
    "Currently, our resources can't afford to have dedicated people to develop and run this kind of process. Lucky for me, I used to be a Data Scientist and r/RAOP+kaggle gives me data to work with.\n",
    "\n",
    "## Business objectives\n",
    "\n",
    "1. Train a model to predict legitimacy *(i.e. pizza donation)* of a request at the moment of request to avoid target leakage.\n",
    "2. Find a process that doesn't disapprove or lower the previous legitimacy of donation at the moment of data retrieval, if there's such a thing.\n",
    "\n",
    "## Future concerns\n",
    "\n",
    "The current depicted design doesn't leverage any concerns about legitimate requests leading to actual donation and marketing performances.\n",
    "Indeed, legitimate requests could be all fulfilled or partially depending on our selection process, volume, donation supply chain, seasonality, cost efficiency, and many other variables.\n",
    "For now, the project focus on donation legitimacy modelisation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from scipy.stats import f_oneway\n",
    "import joblib\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2, SelectKBest\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pizza_raw_data = pd.read_json('../data/pizza_data.json',\n",
    "                              dtype={\"giver_username_if_known\": str,\n",
    "                                     \"number_of_upvotes_of_request_at_retrieval\": int,\n",
    "                                     \"post_was_edited\": bool,\n",
    "                                     \"request_id\": str,\n",
    "                                     \"request_number_of_comments_at_retrieval\": int,\n",
    "                                     \"request_text\": str,\n",
    "                                     \"request_text_edit_aware\": str,\n",
    "                                     \"request_title\": str,\n",
    "                                     \"requester_account_age_in_days_at_request\": float,\n",
    "                                     \"requester_account_age_in_days_at_retrieval\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_request\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_retrieval\": float,\n",
    "                                     \"requester_number_of_comments_at_request\": int,\n",
    "                                     \"requester_number_of_comments_at_retrieval\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_request\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_at_request\": int,\n",
    "                                     \"requester_number_of_posts_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_request\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_subreddits_at_request\": int,\n",
    "                                     \"requester_received_pizza\": bool,\n",
    "                                     \"requester_subreddits_at_request\": list,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_user_flair\": str,\n",
    "                                     \"requester_username\": str,\n",
    "                                     \"unix_timestamp_of_request\": int,\n",
    "                                     \"unix_timestamp_of_request_utc\": int})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4040 entries, 0 to 4039\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   giver_username_if_known                               4040 non-null   object \n",
      " 1   number_of_downvotes_of_request_at_retrieval           4040 non-null   int64  \n",
      " 2   number_of_upvotes_of_request_at_retrieval             4040 non-null   int32  \n",
      " 3   post_was_edited                                       4040 non-null   bool   \n",
      " 4   request_id                                            4040 non-null   object \n",
      " 5   request_number_of_comments_at_retrieval               4040 non-null   int32  \n",
      " 6   request_text                                          4040 non-null   object \n",
      " 7   request_text_edit_aware                               4040 non-null   object \n",
      " 8   request_title                                         4040 non-null   object \n",
      " 9   requester_account_age_in_days_at_request              4040 non-null   float64\n",
      " 10  requester_account_age_in_days_at_retrieval            4040 non-null   float64\n",
      " 11  requester_days_since_first_post_on_raop_at_request    4040 non-null   float64\n",
      " 12  requester_days_since_first_post_on_raop_at_retrieval  4040 non-null   float64\n",
      " 13  requester_number_of_comments_at_request               4040 non-null   int32  \n",
      " 14  requester_number_of_comments_at_retrieval             4040 non-null   int32  \n",
      " 15  requester_number_of_comments_in_raop_at_request       4040 non-null   int32  \n",
      " 16  requester_number_of_comments_in_raop_at_retrieval     4040 non-null   int32  \n",
      " 17  requester_number_of_posts_at_request                  4040 non-null   int32  \n",
      " 18  requester_number_of_posts_at_retrieval                4040 non-null   int32  \n",
      " 19  requester_number_of_posts_on_raop_at_request          4040 non-null   int32  \n",
      " 20  requester_number_of_posts_on_raop_at_retrieval        4040 non-null   int32  \n",
      " 21  requester_number_of_subreddits_at_request             4040 non-null   int32  \n",
      " 22  requester_received_pizza                              4040 non-null   bool   \n",
      " 23  requester_subreddits_at_request                       4040 non-null   object \n",
      " 24  requester_upvotes_minus_downvotes_at_request          4040 non-null   int32  \n",
      " 25  requester_upvotes_minus_downvotes_at_retrieval        4040 non-null   int32  \n",
      " 26  requester_upvotes_plus_downvotes_at_request           4040 non-null   int32  \n",
      " 27  requester_upvotes_plus_downvotes_at_retrieval         4040 non-null   int32  \n",
      " 28  requester_user_flair                                  4040 non-null   object \n",
      " 29  requester_username                                    4040 non-null   object \n",
      " 30  unix_timestamp_of_request                             4040 non-null   int32  \n",
      " 31  unix_timestamp_of_request_utc                         4040 non-null   int32  \n",
      "dtypes: bool(2), float64(4), int32(17), int64(1), object(8)\n",
      "memory usage: 686.6+ KB\n"
     ]
    }
   ],
   "source": [
    "pizza_raw_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset has no missing values, so imputation processes will not be covered in this notebook, but should be considered in a full production-ready pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data leakage prevention\n",
    "\n",
    "Some features may lead to data leakage.\n",
    "One is directly linked to pizza donation, `giver_username_if_known`.\n",
    "Others may be since they aren't concerned about at_request/at_retrieval split-up, such as `requester_user_flair` *(requester badge obtention after receiving a pizza donation)*, `request_text` and `post_was_edited` *(some request posts are edited after getting a pizza donation)*.\n",
    "So, these features are removed from our project."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pizza_prevented_data = pizza_raw_data.loc[:, ~(pizza_raw_data\n",
    "                                               .columns\n",
    "                                               .isin([\"giver_username_if_known\",\n",
    "                                                      \"requester_user_flair\",\n",
    "                                                      \"request_text\",\n",
    "                                                      \"post_was_edited\"]))\n",
    "                       ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "target_name = 'requester_received_pizza'\n",
    "seed = 101\n",
    "X = pizza_prevented_data.copy()\n",
    "y = X.pop(target_name)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=seed, stratify=y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 4040 samples, we'll use 3636 of them to train the model.\n",
      "From 3636 requests, 895 led to a donation, which represents 24.6%.\n",
      "Thus, among 1026 days, 1 pizza was donate every 1.15 day.\n"
     ]
    }
   ],
   "source": [
    "dataset_period = (dt.strptime(\"29/09/2013\", \"%d/%m/%Y\") - dt.strptime(\"08/12/2010\", \"%d/%m/%Y\")).days\n",
    "\n",
    "print(f'''From our {pizza_raw_data.shape[0]} samples, we'll use {X_train.shape[0]} of them to train the model.\n",
    "From {len(y_train)} requests, {y_train.sum()} led to a donation, which represents {round(y_train.sum()/len(y_train), 3)*100}%.\n",
    "Thus, among {dataset_period} days, 1 pizza was donate every {round(dataset_period/y_train.sum(), 2)} day.''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One request out of four is therefore legitimate according to our statements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dissociate features at request from at retrieval\n",
    "\n",
    "In order to avoid data leakage, for example a request that had a donation could have a posteriori some upvotes boost, only features at request time are accounted according to the first objective to model legitimacy of a request."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "univariate_features = [\"unix_timestamp_of_request_utc\", #non-utc timestamp is redundant and less convenient\n",
    "                       \"request_title\",\n",
    "                       \"request_text_edit_aware\"]\n",
    "\n",
    "at_request_features = []\n",
    "at_retrieval_features = []\n",
    "\n",
    "for selected_time, selected_features in {\"at_request\": at_request_features, \"at_retrieval\": at_retrieval_features}.items():\n",
    "    dataset_features = (X_train\n",
    "                        .filter(regex=f'.*{selected_time}$')\n",
    "                        .columns\n",
    "                        .tolist())\n",
    "    selected_features.extend(dataset_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "pizza_retrieval_data = X_train[univariate_features + at_retrieval_features]\n",
    "X_train = X_train[univariate_features + at_request_features]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 raw features can be used to predict legitimacy of a request.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.shape[1]} raw features can be used to predict legitimacy of a request.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "        unix_timestamp_of_request_utc request_title request_text_edit_aware  \\\ncount                    3.636000e+03          3636                    3636   \nunique                            NaN          3625                    3538   \ntop                               NaN       Request                           \nfreq                              NaN             4                      95   \nmean                     1.342677e+09           NaN                     NaN   \nstd                      2.332738e+07           NaN                     NaN   \nmin                      1.297723e+09           NaN                     NaN   \n25%                      1.320252e+09           NaN                     NaN   \n50%                      1.342484e+09           NaN                     NaN   \n75%                      1.364254e+09           NaN                     NaN   \nmax                      1.381523e+09           NaN                     NaN   \n\n        requester_account_age_in_days_at_request  \\\ncount                                3636.000000   \nunique                                       NaN   \ntop                                          NaN   \nfreq                                         NaN   \nmean                                  251.623667   \nstd                                   297.644679   \nmin                                     0.000000   \n25%                                     2.872529   \n50%                                   156.997483   \n75%                                   386.092488   \nmax                                  2521.263206   \n\n        requester_days_since_first_post_on_raop_at_request  \\\ncount                                         3636.000000    \nunique                                                NaN    \ntop                                                   NaN    \nfreq                                                  NaN    \nmean                                            15.827121    \nstd                                             67.651509    \nmin                                              0.000000    \n25%                                              0.000000    \n50%                                              0.000000    \n75%                                              0.000000    \nmax                                            785.457685    \n\n        requester_number_of_comments_at_request  \\\ncount                               3636.000000   \nunique                                      NaN   \ntop                                         NaN   \nfreq                                        NaN   \nmean                                 115.032178   \nstd                                  193.458792   \nmin                                    0.000000   \n25%                                    0.000000   \n50%                                   24.000000   \n75%                                  139.000000   \nmax                                  992.000000   \n\n        requester_number_of_comments_in_raop_at_request  \\\ncount                                       3636.000000   \nunique                                              NaN   \ntop                                                 NaN   \nfreq                                                NaN   \nmean                                           0.646040   \nstd                                            3.323355   \nmin                                            0.000000   \n25%                                            0.000000   \n50%                                            0.000000   \n75%                                            0.000000   \nmax                                           88.000000   \n\n        requester_number_of_posts_at_request  \\\ncount                            3636.000000   \nunique                                   NaN   \ntop                                      NaN   \nfreq                                     NaN   \nmean                               21.363311   \nstd                                50.180486   \nmin                                 0.000000   \n25%                                 0.000000   \n50%                                 5.000000   \n75%                                22.000000   \nmax                               867.000000   \n\n        requester_number_of_posts_on_raop_at_request  \\\ncount                                    3636.000000   \nunique                                           NaN   \ntop                                              NaN   \nfreq                                             NaN   \nmean                                        0.065457   \nstd                                         0.329403   \nmin                                         0.000000   \n25%                                         0.000000   \n50%                                         0.000000   \n75%                                         0.000000   \nmax                                         5.000000   \n\n        requester_number_of_subreddits_at_request  \\\ncount                                 3636.000000   \nunique                                        NaN   \ntop                                           NaN   \nfreq                                          NaN   \nmean                                    18.003850   \nstd                                     21.648384   \nmin                                      0.000000   \n25%                                      1.000000   \n50%                                     11.000000   \n75%                                     27.000000   \nmax                                    186.000000   \n\n       requester_subreddits_at_request  \\\ncount                             3636   \nunique                            2683   \ntop                                 []   \nfreq                               667   \nmean                               NaN   \nstd                                NaN   \nmin                                NaN   \n25%                                NaN   \n50%                                NaN   \n75%                                NaN   \nmax                                NaN   \n\n        requester_upvotes_minus_downvotes_at_request  \\\ncount                                    3636.000000   \nunique                                           NaN   \ntop                                              NaN   \nfreq                                             NaN   \nmean                                     1163.397690   \nstd                                      3853.827389   \nmin                                      -173.000000   \n25%                                         3.000000   \n50%                                       173.500000   \n75%                                      1153.000000   \nmax                                    155010.000000   \n\n        requester_upvotes_plus_downvotes_at_request  \ncount                                  3.636000e+03  \nunique                                          NaN  \ntop                                             NaN  \nfreq                                            NaN  \nmean                                   3.807502e+03  \nstd                                    2.707045e+04  \nmin                                    0.000000e+00  \n25%                                    8.000000e+00  \n50%                                    3.505000e+02  \n75%                                    2.290250e+03  \nmax                                    1.286864e+06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unix_timestamp_of_request_utc</th>\n      <th>request_title</th>\n      <th>request_text_edit_aware</th>\n      <th>requester_account_age_in_days_at_request</th>\n      <th>requester_days_since_first_post_on_raop_at_request</th>\n      <th>requester_number_of_comments_at_request</th>\n      <th>requester_number_of_comments_in_raop_at_request</th>\n      <th>requester_number_of_posts_at_request</th>\n      <th>requester_number_of_posts_on_raop_at_request</th>\n      <th>requester_number_of_subreddits_at_request</th>\n      <th>requester_subreddits_at_request</th>\n      <th>requester_upvotes_minus_downvotes_at_request</th>\n      <th>requester_upvotes_plus_downvotes_at_request</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.636000e+03</td>\n      <td>3636</td>\n      <td>3636</td>\n      <td>3636.000000</td>\n      <td>3636.000000</td>\n      <td>3636.000000</td>\n      <td>3636.000000</td>\n      <td>3636.000000</td>\n      <td>3636.000000</td>\n      <td>3636.000000</td>\n      <td>3636</td>\n      <td>3636.000000</td>\n      <td>3.636000e+03</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>3625</td>\n      <td>3538</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2683</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Request</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>4</td>\n      <td>95</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.342677e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>251.623667</td>\n      <td>15.827121</td>\n      <td>115.032178</td>\n      <td>0.646040</td>\n      <td>21.363311</td>\n      <td>0.065457</td>\n      <td>18.003850</td>\n      <td>NaN</td>\n      <td>1163.397690</td>\n      <td>3.807502e+03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.332738e+07</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>297.644679</td>\n      <td>67.651509</td>\n      <td>193.458792</td>\n      <td>3.323355</td>\n      <td>50.180486</td>\n      <td>0.329403</td>\n      <td>21.648384</td>\n      <td>NaN</td>\n      <td>3853.827389</td>\n      <td>2.707045e+04</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.297723e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>-173.000000</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.320252e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.872529</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>8.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.342484e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>156.997483</td>\n      <td>0.000000</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>11.000000</td>\n      <td>NaN</td>\n      <td>173.500000</td>\n      <td>3.505000e+02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.364254e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>386.092488</td>\n      <td>0.000000</td>\n      <td>139.000000</td>\n      <td>0.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>27.000000</td>\n      <td>NaN</td>\n      <td>1153.000000</td>\n      <td>2.290250e+03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.381523e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2521.263206</td>\n      <td>785.457685</td>\n      <td>992.000000</td>\n      <td>88.000000</td>\n      <td>867.000000</td>\n      <td>5.000000</td>\n      <td>186.000000</td>\n      <td>NaN</td>\n      <td>155010.000000</td>\n      <td>1.286864e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe(include=\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data exploration\n",
    "## Let's start first with non-textual data ...\n",
    "\n",
    "In order to have ground level refrence, let's start with a very basic modelisation with underperforming results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(exclude=[\"object\"])\n",
    "X_val_num = X_val.select_dtypes(exclude=[\"object\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3636 entries, 1186 to 813\n",
      "Data columns (total 10 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   unix_timestamp_of_request_utc                       3636 non-null   int32  \n",
      " 1   requester_account_age_in_days_at_request            3636 non-null   float64\n",
      " 2   requester_days_since_first_post_on_raop_at_request  3636 non-null   float64\n",
      " 3   requester_number_of_comments_at_request             3636 non-null   int32  \n",
      " 4   requester_number_of_comments_in_raop_at_request     3636 non-null   int32  \n",
      " 5   requester_number_of_posts_at_request                3636 non-null   int32  \n",
      " 6   requester_number_of_posts_on_raop_at_request        3636 non-null   int32  \n",
      " 7   requester_number_of_subreddits_at_request           3636 non-null   int32  \n",
      " 8   requester_upvotes_minus_downvotes_at_request        3636 non-null   int32  \n",
      " 9   requester_upvotes_plus_downvotes_at_request         3636 non-null   int32  \n",
      "dtypes: float64(2), int32(8)\n",
      "memory usage: 198.8 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_num.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature engineering\n",
    "\n",
    "Votes give great insights with the sum related to visibility and difference related to consensus/polarisation. However, the 2 variables here are absolute and a relative one is missing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def add_relative_votes(df, num, den, suffix=\"request\"):\n",
    "    math_fct = lambda row: row.iloc[1] and row.iloc[0] / row.iloc[1] or 0\n",
    "    df[f'requester_relative_consensual_votes_at_{suffix}'] = df.copy()[[num, den]].apply(math_fct, axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "diff_votes = 'requester_upvotes_minus_downvotes_at_request'\n",
    "sum_votes = 'requester_upvotes_plus_downvotes_at_request'\n",
    "\n",
    "X_train_num = add_relative_votes(X_train_num, num=diff_votes, den=sum_votes)\n",
    "X_val_num = add_relative_votes(X_val_num, num=diff_votes, den=sum_votes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature importances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def make_mi_scores(x_data, y_data):\n",
    "    mi_results = mutual_info_classif(x_data, y_data, random_state=seed)\n",
    "    mi_results = pd.Series(mi_results, name=\"MI Scores\", index=x_data.columns)\n",
    "    return mi_results\n",
    "\n",
    "def make_f_oneway_scores(x_data, y_data):\n",
    "    grp_anova = x_data.groupby(y_data)\n",
    "\n",
    "    f_values = []\n",
    "    for feat in x_data.columns:\n",
    "        s, p = f_oneway(grp_anova.get_group(0)[feat],\n",
    "                        grp_anova.get_group(1)[feat])\n",
    "        s = round(s, 4)\n",
    "        p = round(p, 4)\n",
    "        f_values.append((s, p))\n",
    "\n",
    "    f_scores = pd.Series(f_values, name=\"F_oneway Scores\", index=x_data.columns)\n",
    "    return f_scores\n",
    "\n",
    "def make_corr_scores(x_data, y_data):\n",
    "    return x_data.corrwith(y_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    Mutual Info  Correlation  \\\nunix_timestamp_of_request_utc                          0.024898    -0.107105   \nrequester_account_age_in_days_at_request               0.000000     0.043291   \nrequester_days_since_first_post_on_raop_at_request     0.002130     0.101339   \nrequester_number_of_comments_at_request                0.000000     0.034051   \nrequester_number_of_comments_in_raop_at_request        0.013583     0.131384   \nrequester_number_of_posts_at_request                   0.006105     0.014886   \nrequester_number_of_posts_on_raop_at_request           0.002615     0.138441   \nrequester_number_of_subreddits_at_request              0.000011     0.038775   \nrequester_upvotes_minus_downvotes_at_request           0.010255     0.031172   \nrequester_upvotes_plus_downvotes_at_request            0.000000     0.025642   \nrequester_relative_consensual_votes_at_request         0.000000     0.080072   \n\n                                                      F_oneway (s,p)  \nunix_timestamp_of_request_utc                         (42.1707, 0.0)  \nrequester_account_age_in_days_at_request             (6.8232, 0.009)  \nrequester_days_since_first_post_on_raop_at_request    (37.7071, 0.0)  \nrequester_number_of_comments_at_request             (4.2183, 0.0401)  \nrequester_number_of_comments_in_raop_at_request       (63.8311, 0.0)  \nrequester_number_of_posts_at_request                (0.8055, 0.3695)  \nrequester_number_of_posts_on_raop_at_request          (71.0095, 0.0)  \nrequester_number_of_subreddits_at_request           (5.4718, 0.0194)  \nrequester_upvotes_minus_downvotes_at_request        (3.5346, 0.0602)  \nrequester_upvotes_plus_downvotes_at_request         (2.3909, 0.1221)  \nrequester_relative_consensual_votes_at_request          (23.45, 0.0)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mutual Info</th>\n      <th>Correlation</th>\n      <th>F_oneway (s,p)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>unix_timestamp_of_request_utc</th>\n      <td>0.024898</td>\n      <td>-0.107105</td>\n      <td>(42.1707, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_account_age_in_days_at_request</th>\n      <td>0.000000</td>\n      <td>0.043291</td>\n      <td>(6.8232, 0.009)</td>\n    </tr>\n    <tr>\n      <th>requester_days_since_first_post_on_raop_at_request</th>\n      <td>0.002130</td>\n      <td>0.101339</td>\n      <td>(37.7071, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_comments_at_request</th>\n      <td>0.000000</td>\n      <td>0.034051</td>\n      <td>(4.2183, 0.0401)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_comments_in_raop_at_request</th>\n      <td>0.013583</td>\n      <td>0.131384</td>\n      <td>(63.8311, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_posts_at_request</th>\n      <td>0.006105</td>\n      <td>0.014886</td>\n      <td>(0.8055, 0.3695)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_posts_on_raop_at_request</th>\n      <td>0.002615</td>\n      <td>0.138441</td>\n      <td>(71.0095, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_subreddits_at_request</th>\n      <td>0.000011</td>\n      <td>0.038775</td>\n      <td>(5.4718, 0.0194)</td>\n    </tr>\n    <tr>\n      <th>requester_upvotes_minus_downvotes_at_request</th>\n      <td>0.010255</td>\n      <td>0.031172</td>\n      <td>(3.5346, 0.0602)</td>\n    </tr>\n    <tr>\n      <th>requester_upvotes_plus_downvotes_at_request</th>\n      <td>0.000000</td>\n      <td>0.025642</td>\n      <td>(2.3909, 0.1221)</td>\n    </tr>\n    <tr>\n      <th>requester_relative_consensual_votes_at_request</th>\n      <td>0.000000</td>\n      <td>0.080072</td>\n      <td>(23.45, 0.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores = make_mi_scores(X_train_num, y_train)\n",
    "f_oneway_scores = make_f_oneway_scores(X_train_num, y_train)\n",
    "corr_scores = make_corr_scores(X_train_num, y_train)\n",
    "\n",
    "pd_info = pd.concat([mi_scores, corr_scores, f_oneway_scores], axis='columns')\n",
    "pd_info.columns =[\"Mutual Info\", \"Correlation\", \"F_oneway (s,p)\"]\n",
    "pd_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that almost all features have some importance, with `requester_number_of_posts_at_request` being the least important of them.\n",
    "The previous created `requester_relative_consensual_votes_at_request` feature looks like a good new addition, and beating its creation features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelisation\n",
    "\n",
    "Now that we're at the modelisation step, there is one important question, which is what metric to use.\n",
    "The real subquestion is, in terms of business, what is more prolific and harmless in the fact of donate to a mostly illegitimate request or on contrary not donating to a legitimate request.\n",
    "The first, a false positive, harms the branding image and financial cost, the other, a false negative, harms notoriety.\n",
    "But most of all, as described earlier, this algorithm doesn't lead directly to donation. It outputs only so-called legitimacy, which will take a big place in the donation decision but still can be hold back on a decision algorithm.\n",
    "With that in mind, the main goal should be to minimize false positives with a metric such as precision, as long as false negatives are not numerous."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def create_scaler_preproc(numerical_features, scaler_method = None):\n",
    "    steps = [('scaler_method', scaler_method)]\n",
    "    scaler_transformer = Pipeline(steps)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('scaler_transformer', scaler_transformer, numerical_features)\n",
    "        ], remainder='drop')\n",
    "\n",
    "    # Model pipeline\n",
    "    steps = [('preproc', preprocessor)]\n",
    "    proc_pipe = Pipeline(steps)\n",
    "\n",
    "    return proc_pipe\n",
    "\n",
    "def create_pipeline(train_set, preproc, estimator, model_name, grid_strat, hyperparameters, n_folds,\n",
    "                    eval_metric='precision', verbosity=3, n_jobs=10):\n",
    "    X, y = train_set\n",
    "\n",
    "    # Model pipeline\n",
    "    steps = [(\"preproc\", preproc), (model_name, estimator)]\n",
    "    model_pipe = Pipeline(steps)\n",
    "\n",
    "    # Grid Search\n",
    "    cv = grid_strat(model_pipe,\n",
    "                    param_grid=hyperparameters,\n",
    "                    cv=n_folds,\n",
    "                    scoring=eval_metric,\n",
    "                    n_jobs=n_jobs,\n",
    "                    verbose=verbosity,\n",
    "                    random_state=seed)\n",
    "\n",
    "    grid_model = cv.fit(X, y)\n",
    "\n",
    "    return grid_model\n",
    "\n",
    "def print_pipe_results(train_set, val_set, model):\n",
    "    X_train, y_train = train_set\n",
    "    yhat = model.best_estimator_.predict(X_train)\n",
    "    print(f'In samples resutls:\\n {classification_report(y_train, yhat)}')\n",
    "    print()\n",
    "\n",
    "    X_val, y_val = val_set\n",
    "    yhat = model.best_estimator_.predict(X_val)\n",
    "    print(f'Out-of-samples resutls:\\n {classification_report(y_val, yhat)}')\n",
    "    print()\n",
    "    print(f'''Confusion matrix:\n",
    "{pd.DataFrame(confusion_matrix(y_val, yhat, normalize='all'),\n",
    "              columns=[\"PredNeg\", \"PredPos\"],\n",
    "              index=[\"Neg\", \"Pos\"])}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.99      0.86      2741\n",
      "        True       0.68      0.04      0.08       895\n",
      "\n",
      "    accuracy                           0.76      3636\n",
      "   macro avg       0.72      0.52      0.47      3636\n",
      "weighted avg       0.74      0.76      0.67      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      1.00      0.87       153\n",
      "        True       1.00      0.06      0.12        49\n",
      "\n",
      "    accuracy                           0.77       202\n",
      "   macro avg       0.88      0.53      0.49       202\n",
      "weighted avg       0.82      0.77      0.69       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.757426  0.000000\n",
      "Pos  0.227723  0.014851\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',\n",
    "                           random_state=seed)\n",
    "\n",
    "model_name = 'logreg'\n",
    "\n",
    "parameters = {f'{model_name}__C': np.logspace(-2, 1, 50)}\n",
    "\n",
    "logreg_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                                preproc=create_scaler_preproc(X_train_num.columns, scaler_method=MaxAbsScaler()),\n",
    "                                estimator = model,\n",
    "                                model_name = model_name,\n",
    "                                grid_strat=HalvingGridSearchCV,\n",
    "                                hyperparameters = parameters,\n",
    "                                n_folds = 3,\n",
    "                                eval_metric='precision',\n",
    "                                verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   val_set = [X_val_num, y_val],\n",
    "                   model = logreg_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression doesn't offer great recall performance whatever the tuning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.93      0.84      2741\n",
      "        True       0.41      0.14      0.21       895\n",
      "\n",
      "    accuracy                           0.74      3636\n",
      "   macro avg       0.59      0.54      0.53      3636\n",
      "weighted avg       0.68      0.74      0.69      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.93      0.84       153\n",
      "        True       0.33      0.10      0.16        49\n",
      "\n",
      "    accuracy                           0.73       202\n",
      "   macro avg       0.55      0.52      0.50       202\n",
      "weighted avg       0.66      0.73      0.68       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.707921  0.049505\n",
      "Pos  0.217822  0.024752\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "model_name = 'gaus_nb'\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "gaussnb_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                                 preproc=create_scaler_preproc(X_train_num.columns, scaler_method=StandardScaler()),\n",
    "                                 estimator = model,\n",
    "                                 model_name = model_name,\n",
    "                                 grid_strat=HalvingGridSearchCV,\n",
    "                                 hyperparameters = parameters,\n",
    "                                 n_folds = 3,\n",
    "                                 eval_metric='precision',\n",
    "                                 verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   val_set = [X_val_num, y_val],\n",
    "                   model = gaussnb_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      1.00      0.88      2741\n",
      "        True       0.94      0.18      0.30       895\n",
      "\n",
      "    accuracy                           0.79      3636\n",
      "   macro avg       0.86      0.59      0.59      3636\n",
      "weighted avg       0.83      0.79      0.74      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.97      0.86       153\n",
      "        True       0.56      0.10      0.17        49\n",
      "\n",
      "    accuracy                           0.76       202\n",
      "   macro avg       0.66      0.54      0.52       202\n",
      "weighted avg       0.72      0.76      0.69       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.737624  0.019802\n",
      "Pos  0.217822  0.024752\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=seed, n_jobs=10)\n",
    "\n",
    "model_name = 'rf'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(8, 100, 8).astype(int),\n",
    "              f'{model_name}__max_depth': np.linspace(2, 8, 8).astype(int)}\n",
    "\n",
    "rf_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                            preproc=create_scaler_preproc(X_train_num.columns, scaler_method=None),\n",
    "                            estimator = model,\n",
    "                            model_name = model_name,\n",
    "                            grid_strat=HalvingGridSearchCV,\n",
    "                            hyperparameters = parameters,\n",
    "                            n_folds = 3,\n",
    "                            eval_metric='f1', #better overall, little downgrade on precision high boost on recall\n",
    "                            verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   val_set = [X_val_num, y_val],\n",
    "                   model = rf_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGBoost Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 134\n",
      "max_resources_: 3636\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 48\n",
      "n_resources: 134\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 16\n",
      "n_resources: 402\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 6\n",
      "n_resources: 1206\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 3618\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.99      0.87      2741\n",
      "        True       0.82      0.15      0.25       895\n",
      "\n",
      "    accuracy                           0.78      3636\n",
      "   macro avg       0.80      0.57      0.56      3636\n",
      "weighted avg       0.79      0.78      0.72      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.98      0.86       153\n",
      "        True       0.62      0.10      0.18        49\n",
      "\n",
      "    accuracy                           0.77       202\n",
      "   macro avg       0.70      0.54      0.52       202\n",
      "weighted avg       0.74      0.77      0.70       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.742574  0.014851\n",
      "Pos  0.217822  0.024752\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=seed,\n",
    "                          objective='binary:logistic',\n",
    "                          eval_metric=precision_score,\n",
    "                          tree_method='gpu_hist')\n",
    "\n",
    "model_name = 'xgb_cl'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(30, 60, 4).astype(int),\n",
    "              f'{model_name}__learning_rate': np.logspace(-1.5, -0.5, 4),\n",
    "              f'{model_name}__max_depth': np.linspace(2, 7, 3).astype(int),\n",
    "              # f'{model_name}__colsample_bytree': np.logspace(-0.7, 0, 2),\n",
    "              # f'{model_name}__subsample': np.logspace(-0.7, 0, 2)\n",
    "             }\n",
    "\n",
    "xgb_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                             preproc=create_scaler_preproc(X_train_num.columns, scaler_method=None),\n",
    "                             estimator = model,\n",
    "                             model_name = model_name,\n",
    "                             grid_strat=HalvingGridSearchCV,\n",
    "                             hyperparameters = parameters,\n",
    "                             n_folds = 3,\n",
    "                             eval_metric='precision', # f1 is bad -> 0.47 precision / 0.46 recall\n",
    "                             verbosity=1)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   val_set = [X_val_num, y_val],\n",
    "                   model = xgb_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion\n",
    "\n",
    "After model comparison and light hypertunings, results aren't very conclusive. It was expected with only these variables *(backed up by the features importance part)*.\n",
    "It seems that predicting precisely positive class is quite challenging with the current process.\n",
    "Let's move to textual modelisation to pump up our game."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ... and get the final word."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X_train_text = X_train.select_dtypes(include=[\"object\"])\n",
    "X_val_text = X_val.select_dtypes(include=[\"object\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3636 entries, 1186 to 813\n",
      "Data columns (total 3 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   request_title                    3636 non-null   object\n",
      " 1   request_text_edit_aware          3636 non-null   object\n",
      " 2   requester_subreddits_at_request  3636 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 113.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_text.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only `request_title` and `request_text_edit_aware` are NLP oriented features, so it'll be the main focus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Cleaning\n",
    "\n",
    "In order to process textual data, a data cleaning process is required, in order to standardize case sensitivity and too little or not enough word occurrences.\n",
    "On a second step, we can try different process to search for improvements, such as stemming/lemmanization and other techniques.\n",
    "\n",
    "To get there, we can use a useful function of scikit-learn that handles tokenization, stop words removal, and BOW process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "stopwords_en = set(stopwords.words('english')).union(set(string.punctuation))\n",
    "stopwords_en = stopwords_en.union(word_tokenize(' '.join(stopwords_en)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelisation\n",
    "\n",
    "Like non-textual data, we can repeat the modelisation step and get some comparisons."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def create_nlp_preproc(post_feature, title_feature, reducter=None, scaler=None):\n",
    "    # Word vectorizers\n",
    "    # Post data\n",
    "    text_vectorizer = CountVectorizer(lowercase=True,\n",
    "                                      tokenizer=word_tokenize,\n",
    "                                      token_pattern=None,\n",
    "                                      stop_words=list(stopwords_en),\n",
    "                                      min_df=3,\n",
    "                                      ngram_range=(1,2))\n",
    "    text_tfidf = TfidfTransformer()\n",
    "    text_reduc = reducter\n",
    "    text_scaler = scaler\n",
    "    steps = [('text_count', text_vectorizer), ('text_tfidf', text_tfidf), ('text_reduc', text_reduc), ('text_scaler', text_scaler)]\n",
    "    text_pipe = Pipeline(steps)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('wordvec_post_transformer', text_pipe, post_feature),\n",
    "            ('wordvec_title_transformer', text_pipe, title_feature)\n",
    "        ], remainder='drop')\n",
    "\n",
    "    steps = [('preproc', preprocessor)]\n",
    "    preproc_pipe = Pipeline(steps)\n",
    "\n",
    "    return preproc_pipe\n",
    "\n",
    "def create_nlp_pipeline(train_set, preproc, estimator, model_name, grid_strat, hyperparameters, n_folds,\n",
    "                        eval_metric='precision', verbosity=1, n_jobs=10):\n",
    "    X, y = train_set\n",
    "\n",
    "    # Model pipeline\n",
    "    steps = [(\"preproc\", preproc), (model_name, estimator)]\n",
    "    model_pipe = Pipeline(steps)\n",
    "\n",
    "    # Grid Search\n",
    "    cv = grid_strat(model_pipe,\n",
    "                    param_grid=hyperparameters,\n",
    "                    cv=n_folds,\n",
    "                    scoring=eval_metric,\n",
    "                    n_jobs=n_jobs,\n",
    "                    verbose=verbosity,\n",
    "                    random_state=seed)\n",
    "\n",
    "    grid_model = cv.fit(X, y)\n",
    "\n",
    "    return grid_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      1.00      0.89      2741\n",
      "        True       1.00      0.28      0.44       895\n",
      "\n",
      "    accuracy                           0.82      3636\n",
      "   macro avg       0.90      0.64      0.67      3636\n",
      "weighted avg       0.86      0.82      0.78      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.97      0.85       153\n",
      "        True       0.33      0.04      0.07        49\n",
      "\n",
      "    accuracy                           0.75       202\n",
      "   macro avg       0.55      0.51      0.46       202\n",
      "weighted avg       0.66      0.75      0.66       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.737624  0.019802\n",
      "Pos  0.232673  0.009901\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',\n",
    "                           random_state=seed)\n",
    "\n",
    "model_name = 'logreg_nlp'\n",
    "\n",
    "parameters = {f'{model_name}__C': np.logspace(-1, 0, 15)}\n",
    "\n",
    "logreg_nlp_gridCV = create_nlp_pipeline(train_set = [X_train_text, y_train],\n",
    "                                        preproc=create_nlp_preproc(post_feature='request_text_edit_aware',\n",
    "                                                                   title_feature='request_title',\n",
    "                                                                   scaler=Normalizer()),\n",
    "                                        estimator = model,\n",
    "                                        model_name = model_name,\n",
    "                                        grid_strat=HalvingGridSearchCV,\n",
    "                                        hyperparameters = parameters,\n",
    "                                        n_folds = 3,\n",
    "                                        eval_metric='precision',\n",
    "                                        verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_text, y_train],\n",
    "                   val_set = [X_val_text, y_val],\n",
    "                   model = logreg_nlp_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.87      2741\n",
      "        True       1.00      0.04      0.09       895\n",
      "\n",
      "    accuracy                           0.76      3636\n",
      "   macro avg       0.88      0.52      0.48      3636\n",
      "weighted avg       0.82      0.76      0.67      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.86       153\n",
      "        True       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.76       202\n",
      "   macro avg       0.38      0.50      0.43       202\n",
      "weighted avg       0.57      0.76      0.65       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg  PredPos\n",
      "Neg  0.757426      0.0\n",
      "Pos  0.242574      0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "model_name = 'gaus_nb'\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "gaussnb_nlp_gridCV = create_nlp_pipeline(train_set = [X_train_text, y_train],\n",
    "                                         preproc=create_nlp_preproc(post_feature='request_text_edit_aware',\n",
    "                                                                    title_feature='request_title',\n",
    "                                                                    scaler=None,\n",
    "                                                                    reducter=None),\n",
    "                                         estimator = model,\n",
    "                                         model_name = model_name,\n",
    "                                         grid_strat=HalvingGridSearchCV,\n",
    "                                         hyperparameters = parameters,\n",
    "                                         n_folds = 3,\n",
    "                                         eval_metric='precision',\n",
    "                                         verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_text, y_train],\n",
    "                   val_set = [X_val_text, y_val],\n",
    "                   model = gaussnb_nlp_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.86      2741\n",
      "        True       1.00      0.02      0.05       895\n",
      "\n",
      "    accuracy                           0.76      3636\n",
      "   macro avg       0.88      0.51      0.45      3636\n",
      "weighted avg       0.82      0.76      0.66      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.86       153\n",
      "        True       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.76       202\n",
      "   macro avg       0.38      0.50      0.43       202\n",
      "weighted avg       0.57      0.76      0.65       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg  PredPos\n",
      "Neg  0.757426      0.0\n",
      "Pos  0.242574      0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=seed, n_jobs=10)\n",
    "\n",
    "model_name = 'rf'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(50, 500, 4).astype(int),\n",
    "              f'{model_name}__max_depth': np.linspace(1, 25, 4).astype(int)}\n",
    "\n",
    "rf_nlp_gridCV = create_nlp_pipeline(train_set = [X_train_text, y_train],\n",
    "                                    preproc=create_nlp_preproc(post_feature='request_text_edit_aware',\n",
    "                                                               title_feature='request_title'),\n",
    "                                    estimator = model,\n",
    "                                    model_name = model_name,\n",
    "                                    grid_strat=HalvingGridSearchCV,\n",
    "                                    hyperparameters = parameters,\n",
    "                                    n_folds = 3,\n",
    "                                    eval_metric='precision',\n",
    "                                    verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_text, y_train],\n",
    "                   val_set = [X_val_text, y_val],\n",
    "                   model = rf_nlp_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGBoost Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 134\n",
      "max_resources_: 3636\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 72\n",
      "n_resources: 134\n",
      "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 24\n",
      "n_resources: 402\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 8\n",
      "n_resources: 1206\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 3618\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.39      0.52      2741\n",
      "        True       0.26      0.66      0.37       895\n",
      "\n",
      "    accuracy                           0.45      3636\n",
      "   macro avg       0.52      0.52      0.44      3636\n",
      "weighted avg       0.65      0.45      0.48      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.39      0.52       153\n",
      "        True       0.25      0.65      0.37        49\n",
      "\n",
      "    accuracy                           0.45       202\n",
      "   macro avg       0.52      0.52      0.44       202\n",
      "weighted avg       0.65      0.45      0.48       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.292079  0.465347\n",
      "Pos  0.084158  0.158416\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=seed,\n",
    "                          objective='binary:logistic',\n",
    "                          eval_metric=precision_score,\n",
    "                          tree_method='gpu_hist')\n",
    "\n",
    "model_name = 'xgb_cl'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(20, 500, 3).astype(int),\n",
    "              f'{model_name}__learning_rate': np.logspace(-1, 0, 2),\n",
    "              f'{model_name}__max_depth': np.linspace(2, 9, 3).astype(int),\n",
    "              f'{model_name}__booster': ['gbtree'],\n",
    "              f'{model_name}__colsample_bytree': np.logspace(-0.7, 0, 2),\n",
    "              f'{model_name}__subsample': np.logspace(-0.7, 0, 2)\n",
    "             }\n",
    "\n",
    "xgb_nlp_gridCV = create_nlp_pipeline(train_set = [X_train_text, y_train],\n",
    "                                     preproc=create_nlp_preproc(post_feature='request_text_edit_aware',\n",
    "                                                                title_feature='request_title'),\n",
    "                                     estimator = model,\n",
    "                                     model_name = model_name,\n",
    "                                     grid_strat=HalvingGridSearchCV,\n",
    "                                     hyperparameters = parameters,\n",
    "                                     n_folds = 4,\n",
    "                                     eval_metric='precision',\n",
    "                                     verbosity=1)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_text, y_train],\n",
    "                   val_set = [X_val_text, y_val],\n",
    "                   model = xgb_nlp_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion\n",
    "\n",
    "After model comparison and light hypertunings, results are much more encouraging.\n",
    "Let's conclude with a final part incorporating all data types."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One model to rule them all.\n",
    "\n",
    "### Feature engineering\n",
    "\n",
    "Let's add previous feature creation process, as well as a numeric one based on the text length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def add_text_length(df):\n",
    "    post_feat = 'request_text_edit_aware'\n",
    "    df[[f'{post_feat}_len']] = df.copy()[[post_feat]].apply(len)\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_lotr = add_text_length(X_train)\n",
    "X_val_lotr = add_text_length(X_val)\n",
    "X_test_lotr = add_text_length(X_test)\n",
    "\n",
    "diff_votes = 'requester_upvotes_minus_downvotes_at_request'\n",
    "sum_votes = 'requester_upvotes_plus_downvotes_at_request'\n",
    "\n",
    "X_train_lotr = add_relative_votes(X_train_lotr, num=diff_votes, den=sum_votes)\n",
    "X_val_lotr = add_relative_votes(X_val_lotr, num=diff_votes, den=sum_votes)\n",
    "X_test_lotr = add_relative_votes(X_test_lotr, num=diff_votes, den=sum_votes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def create_lotr_preproc(numerical_features, post_feature, title_feature, scaler_num=None, scaler_text=None, reducter=None):\n",
    "    # Non-textual data\n",
    "    steps = [('scaler_method', scaler_num)]\n",
    "    scaler_transformer = Pipeline(steps)\n",
    "\n",
    "    # Word vectorizers\n",
    "    # Textual data\n",
    "    text_vectorizer = CountVectorizer(lowercase=True,\n",
    "                                      tokenizer=word_tokenize,\n",
    "                                      token_pattern=None,\n",
    "                                      stop_words=list(stopwords_en),\n",
    "                                      min_df=4,\n",
    "                                      ngram_range=(1, 2))\n",
    "    text_tfidf = TfidfTransformer()\n",
    "    steps = [('text_count', text_vectorizer), ('text_tfidf', text_tfidf), ('text_reduc', reducter), ('text_scaler', scaler_text)]\n",
    "    text_pipe = Pipeline(steps)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num_transformer', scaler_transformer, numerical_features),\n",
    "            ('wordvec_post_transformer', text_pipe, post_feature),\n",
    "            ('wordvec_title_transformer', text_pipe, title_feature),\n",
    "        ], remainder='drop')\n",
    "\n",
    "    steps = [('preproc', preprocessor)]\n",
    "    preproc_pipe = Pipeline(steps)\n",
    "\n",
    "    return preproc_pipe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      1.00      0.89      2741\n",
      "        True       1.00      0.25      0.39       895\n",
      "\n",
      "    accuracy                           0.81      3636\n",
      "   macro avg       0.90      0.62      0.64      3636\n",
      "weighted avg       0.85      0.81      0.77      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.97      0.85       153\n",
      "        True       0.29      0.04      0.07        49\n",
      "\n",
      "    accuracy                           0.74       202\n",
      "   macro avg       0.52      0.50      0.46       202\n",
      "weighted avg       0.64      0.74      0.66       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.732673  0.024752\n",
      "Pos  0.232673  0.009901\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',\n",
    "                           random_state=seed)\n",
    "\n",
    "model_name = 'logreg_lotr'\n",
    "\n",
    "parameters = {f'{model_name}__C': np.logspace(-1, 0, 40)}\n",
    "\n",
    "logreg_lotr_gridCV = create_nlp_pipeline(train_set = [X_train_lotr, y_train],\n",
    "                                         preproc=create_lotr_preproc(numerical_features=X_train_lotr.select_dtypes(exclude=[\"object\"]).columns,\n",
    "                                                                     post_feature='request_text_edit_aware',\n",
    "                                                                     title_feature='request_title',\n",
    "                                                                     scaler_num=Normalizer()),\n",
    "                                         estimator = model,\n",
    "                                         model_name = model_name,\n",
    "                                         grid_strat=HalvingGridSearchCV,\n",
    "                                         hyperparameters = parameters,\n",
    "                                         n_folds = 3,\n",
    "                                         eval_metric='precision',\n",
    "                                         verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_lotr, y_train],\n",
    "                   val_set = [X_val_lotr, y_val],\n",
    "                   model = logreg_lotr_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This time the logistic regression is quite better both in precision and in accuracy, but still have a margin of improvements in recall."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      1.00      0.87      2741\n",
      "        True       1.00      0.06      0.12       895\n",
      "\n",
      "    accuracy                           0.77      3636\n",
      "   macro avg       0.88      0.53      0.49      3636\n",
      "weighted avg       0.82      0.77      0.68      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.86       153\n",
      "        True       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.76       202\n",
      "   macro avg       0.38      0.50      0.43       202\n",
      "weighted avg       0.57      0.76      0.65       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg  PredPos\n",
      "Neg  0.757426      0.0\n",
      "Pos  0.242574      0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "model_name = 'gausnb_lotr'\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "gaussnb_lotr_gridCV = create_nlp_pipeline(train_set = [X_train_lotr, y_train],\n",
    "                                         preproc=create_lotr_preproc(numerical_features=X_train_lotr.select_dtypes(exclude=[\"object\"]).columns,\n",
    "                                                                     post_feature='request_text_edit_aware',\n",
    "                                                                     title_feature='request_title',\n",
    "                                                                     scaler_num=MinMaxScaler()),\n",
    "                                         estimator = model,\n",
    "                                         model_name = model_name,\n",
    "                                         grid_strat=HalvingGridSearchCV,\n",
    "                                         hyperparameters = parameters,\n",
    "                                         n_folds = 3,\n",
    "                                         eval_metric='precision',\n",
    "                                         verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_lotr, y_train],\n",
    "                   val_set = [X_val_lotr, y_val],\n",
    "                   model = gaussnb_lotr_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.86      2741\n",
      "        True       1.00      0.04      0.08       895\n",
      "\n",
      "    accuracy                           0.76      3636\n",
      "   macro avg       0.88      0.52      0.47      3636\n",
      "weighted avg       0.82      0.76      0.67      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.86       153\n",
      "        True       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.76       202\n",
      "   macro avg       0.38      0.50      0.43       202\n",
      "weighted avg       0.57      0.76      0.65       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg  PredPos\n",
      "Neg  0.757426      0.0\n",
      "Pos  0.242574      0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=seed, n_jobs=10)\n",
    "\n",
    "model_name = 'rf_lotr'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(10, 350, 5).astype(int),\n",
    "              f'{model_name}__max_depth': np.linspace(2, 20, 7).astype(int)}\n",
    "\n",
    "rf_lotr_gridCV = create_nlp_pipeline(train_set = [X_train_lotr, y_train],\n",
    "                                    preproc=create_lotr_preproc(numerical_features=X_train_lotr.select_dtypes(exclude=[\"object\"]).columns,\n",
    "                                                                post_feature='request_text_edit_aware',\n",
    "                                                                title_feature='request_title'),\n",
    "                                    estimator = model,\n",
    "                                    model_name = model_name,\n",
    "                                    grid_strat=HalvingGridSearchCV,\n",
    "                                    hyperparameters = parameters,\n",
    "                                    n_folds = 3,\n",
    "                                    eval_metric='precision',\n",
    "                                    verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_lotr, y_train],\n",
    "                   val_set = [X_val_lotr, y_val],\n",
    "                   model = rf_lotr_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGBoost Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00      2741\n",
      "        True       1.00      0.99      1.00       895\n",
      "\n",
      "    accuracy                           1.00      3636\n",
      "   macro avg       1.00      1.00      1.00      3636\n",
      "weighted avg       1.00      1.00      1.00      3636\n",
      "\n",
      "\n",
      "Out-of-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.91      0.84       153\n",
      "        True       0.46      0.24      0.32        49\n",
      "\n",
      "    accuracy                           0.75       202\n",
      "   macro avg       0.63      0.58      0.58       202\n",
      "weighted avg       0.71      0.75      0.72       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.688119  0.069307\n",
      "Pos  0.183168  0.059406\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=seed,\n",
    "                          objective='binary:logistic',\n",
    "                          eval_metric=precision_score,\n",
    "                          tree_method='gpu_hist',\n",
    "                          n_jobs=10)\n",
    "\n",
    "model_name = 'xgb_cl_lotr'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(150, 400, 3).astype(int),\n",
    "              f'{model_name}__learning_rate': np.logspace(-1.5, -0.5, 4),\n",
    "              f'{model_name}__max_depth': np.linspace(4, 10, 3).astype(int),\n",
    "              f'{model_name}__booster': ['gbtree'],\n",
    "              f'{model_name}__colsample_bytree': np.logspace(-0.7, 0, 3),\n",
    "              f'{model_name}__subsample': np.logspace(-0.1, 0, 2)\n",
    "             }\n",
    "\n",
    "xgb_lotr_gridCV = create_nlp_pipeline(train_set = [X_train_lotr, y_train],\n",
    "                                      preproc=create_lotr_preproc(numerical_features=X_train_lotr.select_dtypes(exclude=[\"object\"]).columns,\n",
    "                                                                  post_feature='request_text_edit_aware',\n",
    "                                                                  title_feature='request_title',\n",
    "                                                                  reducter=NMF(random_state=seed, n_components=100)\n",
    "                                                                  ),\n",
    "                                      estimator = model,\n",
    "                                      model_name = model_name,\n",
    "                                      grid_strat=HalvingGridSearchCV,\n",
    "                                      hyperparameters = parameters,\n",
    "                                      n_folds = 3,\n",
    "                                      eval_metric='f1',\n",
    "                                      verbosity=0)\n",
    "\n",
    "print()\n",
    "print_pipe_results(train_set = [X_train_lotr, y_train],\n",
    "                   val_set = [X_val_lotr, y_val],\n",
    "                   model = xgb_lotr_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "xgb_lotr_model = xgb_lotr_gridCV.best_estimator_\n",
    "#joblib.dump(xgb_lotr_model, f'../models/xgb_nlp_f1_pipeline.joblib')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion\n",
    "\n",
    "As expected, all variables inclusion brings some better performances. Nonetheless, overall performances aren't very satisfying. Indeed, even if precision gets good values, recall is very hard to increase whatever the hypertuning and model.\n",
    "Precision is our goal metric, but recall values are flirting with zero, leading to a model predicting very frequently almost all samples negatively.\n",
    "In that regard the last xgboost model is tune towards f1-score metric to balance false negatives by adding a little more false positives compared to the used of precision as the evaluation metric.\n",
    "Even if the model is obviously overfitting data, it's so far the best result/hypertune on validation set. Thus, that'll be the final model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data validation\n",
    "\n",
    "As described in the beginning, the last objective, if achievable, is to add some retrospectively validation step of the algorithm's prediction of requests legitimacy.\n",
    "Our main tool would be the votes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "pizza_retrieval_data = add_relative_votes(pizza_retrieval_data,\n",
    "                                          num=\"requester_upvotes_minus_downvotes_at_retrieval\",\n",
    "                                          den=\"requester_upvotes_plus_downvotes_at_retrieval\",\n",
    "                                          suffix=\"retrieval\")\n",
    "\n",
    "retriv_features = [\"requester_relative_consensual_votes_at_retrieval\"]\n",
    "request_features = [\"requester_relative_consensual_votes_at_request\"]\n",
    "\n",
    "X_train_retro = pd.concat([X_train_num[request_features], pizza_retrieval_data[retriv_features]],\n",
    "                          axis=\"columns\")\n",
    "\n",
    "def add_relative_votes_change(df):\n",
    "    df = df.copy()\n",
    "    for retriv_feat, request_feat in list(zip(retriv_features, request_features)):\n",
    "        df[f\"{retriv_feat.rpartition('_')[0].rpartition('_')[0]}_change\"] = df[retriv_feat] - df[request_feat]\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_retro = add_relative_votes_change(X_train_retro)\n",
    "\n",
    "yhat_train = pd.Series(xgb_lotr_model.predict(X_train_lotr),\n",
    "                       index=X_train_lotr.index,\n",
    "                       name=\"request_was_legitimate_prediction\")\n",
    "\n",
    "def add_retro_legitimacy_insight(df, true_target, p=5):\n",
    "    df = df.copy()\n",
    "    df[f\"request_was_legitimate_{p}percent\"] = np.logical_and(df[\"requester_relative_consensual_votes_change\"] < p/100, true_target)\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_retro = add_retro_legitimacy_insight(X_train_retro, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "X_val_retro = X.loc[X_val.index, [\"requester_upvotes_minus_downvotes_at_request\",\n",
    "                                  \"requester_upvotes_plus_downvotes_at_request\",\n",
    "                                  \"requester_upvotes_minus_downvotes_at_retrieval\",\n",
    "                                  \"requester_upvotes_plus_downvotes_at_retrieval\"]]\n",
    "\n",
    "X_val_retro = add_relative_votes(X_val_retro,\n",
    "                                 num=\"requester_upvotes_minus_downvotes_at_request\",\n",
    "                                 den=\"requester_upvotes_plus_downvotes_at_request\",)\n",
    "X_val_retro = add_relative_votes(X_val_retro,\n",
    "                                 num=\"requester_upvotes_minus_downvotes_at_retrieval\",\n",
    "                                 den=\"requester_upvotes_plus_downvotes_at_retrieval\",\n",
    "                                 suffix=\"retrieval\")\n",
    "\n",
    "X_val_retro = add_relative_votes_change(X_val_retro)\n",
    "\n",
    "yhat_val = pd.Series(xgb_lotr_model.predict(X_val_lotr),\n",
    "                     index=X_val_lotr.index,\n",
    "                     name=\"request_was_legitimate_prediction\")\n",
    "\n",
    "X_val_retro = add_retro_legitimacy_insight(X_val_retro, y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: ylabel='Frequency'>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_retro[\"requester_relative_consensual_votes_change\"].plot(kind=\"hist\", bins=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "request_was_legitimate_prediction     False     True \nrequest_was_legitimate_5percent                      \nFalse                              0.754675  0.089384\nTrue                               0.001100  0.154840",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>request_was_legitimate_prediction</th>\n      <th>False</th>\n      <th>True</th>\n    </tr>\n    <tr>\n      <th>request_was_legitimate_5percent</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>0.754675</td>\n      <td>0.089384</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>0.001100</td>\n      <td>0.154840</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(X_train_retro[\"request_was_legitimate_5percent\"], yhat_train.astype(bool),\n",
    "            normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "request_was_legitimate_prediction     False     True \nrequest_was_legitimate_5percent                      \nFalse                              0.762376  0.084158\nTrue                               0.108911  0.044554",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>request_was_legitimate_prediction</th>\n      <th>False</th>\n      <th>True</th>\n    </tr>\n    <tr>\n      <th>request_was_legitimate_5percent</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>0.762376</td>\n      <td>0.084158</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>0.108911</td>\n      <td>0.044554</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(X_val_retro[\"request_was_legitimate_5percent\"], yhat_val.astype(bool),\n",
    "            normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "According to the fact that requests were illegitimately labelled when the relative *(i.e. divided by total number of votes)* difference between up/down votes *(consensual/polarizing request)* changed downward over 5% at the moment of retrieval, it appears that some of our predictions were mislabelled.\n",
    "Performances are quite satisfying given the modelisation context. Downgrades are probably due to our modelisation as we can observe it with the validation set, where false negatives bumped up from train to validation set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project conclusion\n",
    "\n",
    "Finally, non-textual and textual data were both important with their relative weights. But as expected, textual data is the heart of modelisation.\n",
    "After many model and hypertuning trys, xgboost was a good candidate while combining it with a relevant preprocessing step. However, the algorithm is relatively strict about false negatives and leads to +/- poor recall performances."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ground truth 24.6% of request leading to donation, our algorithm predicted 12.4% of legitimate requests leading directly to donation.\n",
      "It represents 50.4% of good calls on legitimate request.\n"
     ]
    }
   ],
   "source": [
    "pred_donation_pct = round(xgb_lotr_model.predict(X_test_lotr).sum() / len(xgb_lotr_model.predict(X_test_lotr)), 3) * 100\n",
    "real_donation_pct = round(y.sum()/len(y), 3)*100\n",
    "\n",
    "print(f'''From ground truth {round(y.sum()/len(y), 3)*100}% of request leading to donation, our algorithm predicted {pred_donation_pct}% of legitimate requests leading directly to donation.\n",
    "It represents {round(pred_donation_pct/real_donation_pct, 3)*100}% of good calls on legitimate request.''')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
