{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project hypotheses\n",
    "\n",
    "## Localization\n",
    "\n",
    "Current data come from a supposedly wide audience, since Reddit is a well-known tool in the US.\n",
    "The first hypothesis states that Reddit utilisation doesn't apply a strong input filtering of the relevant population, thus biasing the dataset towards a subpopulation.\n",
    "Second hypothesis is that business context and targeted population are sufficiently similar to the dataset population, even if the location is different, such as in France where Reddit has less coverage.\n",
    "\n",
    "## Time shift\n",
    "\n",
    "Even if at current state (2022/12/26), r/RAOP rules have strong emphasis on the relative legitimacy (reddit account metadata) of applicants to avoid inappropriate requests, they cannot be taken into account here.\n",
    "Indeed, they may have evolved over time, which already adds bias to the historical data, but obviously cannot be applied retrospectively now, 9 years later.\n",
    "Nonetheless, we assume that altruism is a time constant through a wide population.\n",
    "World-wide economic situation shift over time is also neglected since our business object is a vital food product, ðŸš€ popular, and still affordable.\n",
    "\n",
    "## Wisdom of crowds\n",
    "\n",
    "Even if we disregard the rules process, Reddit structure (comments, votes, account metadata) is assimilated to an influence soft-voting tool.\n",
    "That's why it's assumed that donation process and request legitimacy are not misplaced, and we're confident about the transfert between RAOP donation purpose and our business objective.\n",
    "So if a request led to a donation, thus the request was legitimate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Business context\n",
    "\n",
    "## Marketing campaign\n",
    "\n",
    "I'm running a pizza restaurant at a fast-growing pace with some few localizations.\n",
    "In order to promote our upcoming additional location, we're launching a marketing campaign to donate some pizza to people who made a request.\n",
    "It can leverage some pain points:\n",
    "+ Expand our brand image\n",
    "+ Minimize unsells waste\n",
    "+ Donate to people in need\n",
    "\n",
    "Currently, our resources can't afford to have dedicated people to develop and run this kind of process. Lucky for me, I used to be a Data Scientist and r/RAOP+kaggle gives me data to work with.\n",
    "\n",
    "## Business objectives\n",
    "\n",
    "1. Train a model to predict legitimacy *(i.e. pizza donation)* of a request at the moment of request to avoid target leakage.\n",
    "2. Find a process that doesn't disapprove or lower the previous legitimacy of donation at the moment of data retrieval, if there's such a thing.\n",
    "\n",
    "## Future concerns\n",
    "\n",
    "The current depicted design doesn't leverage any concerns about legitimate requests leading to actual donation and marketing performances.\n",
    "Indeed, legitimate requests could be all fulfilled or partially depending on our selection process, volume, donation supply chain, seasonality, cost efficiency, and many other variables.\n",
    "For now, the project focus on donation legitimacy modelisation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from scipy.stats import f_oneway\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pizza_raw_data = pd.read_json('../data/pizza_data.json',\n",
    "                              dtype={\"giver_username_if_known\": str,\n",
    "                                     \"number_of_upvotes_of_request_at_retrieval\": int,\n",
    "                                     \"post_was_edited\": bool,\n",
    "                                     \"request_id\": str,\n",
    "                                     \"request_number_of_comments_at_retrieval\": int,\n",
    "                                     \"request_text\": str,\n",
    "                                     \"request_text_edit_aware\": str,\n",
    "                                     \"request_title\": str,\n",
    "                                     \"requester_account_age_in_days_at_request\": float,\n",
    "                                     \"requester_account_age_in_days_at_retrieval\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_request\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_retrieval\": float,\n",
    "                                     \"requester_number_of_comments_at_request\": int,\n",
    "                                     \"requester_number_of_comments_at_retrieval\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_request\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_at_request\": int,\n",
    "                                     \"requester_number_of_posts_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_request\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_subreddits_at_request\": int,\n",
    "                                     \"requester_received_pizza\": bool,\n",
    "                                     \"requester_subreddits_at_request\": list,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_user_flair\": str,\n",
    "                                     \"requester_username\": str,\n",
    "                                     \"unix_timestamp_of_request\": int,\n",
    "                                     \"unix_timestamp_of_request_utc\": int})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4040 entries, 0 to 4039\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   giver_username_if_known                               4040 non-null   object \n",
      " 1   number_of_downvotes_of_request_at_retrieval           4040 non-null   int64  \n",
      " 2   number_of_upvotes_of_request_at_retrieval             4040 non-null   int32  \n",
      " 3   post_was_edited                                       4040 non-null   bool   \n",
      " 4   request_id                                            4040 non-null   object \n",
      " 5   request_number_of_comments_at_retrieval               4040 non-null   int32  \n",
      " 6   request_text                                          4040 non-null   object \n",
      " 7   request_text_edit_aware                               4040 non-null   object \n",
      " 8   request_title                                         4040 non-null   object \n",
      " 9   requester_account_age_in_days_at_request              4040 non-null   float64\n",
      " 10  requester_account_age_in_days_at_retrieval            4040 non-null   float64\n",
      " 11  requester_days_since_first_post_on_raop_at_request    4040 non-null   float64\n",
      " 12  requester_days_since_first_post_on_raop_at_retrieval  4040 non-null   float64\n",
      " 13  requester_number_of_comments_at_request               4040 non-null   int32  \n",
      " 14  requester_number_of_comments_at_retrieval             4040 non-null   int32  \n",
      " 15  requester_number_of_comments_in_raop_at_request       4040 non-null   int32  \n",
      " 16  requester_number_of_comments_in_raop_at_retrieval     4040 non-null   int32  \n",
      " 17  requester_number_of_posts_at_request                  4040 non-null   int32  \n",
      " 18  requester_number_of_posts_at_retrieval                4040 non-null   int32  \n",
      " 19  requester_number_of_posts_on_raop_at_request          4040 non-null   int32  \n",
      " 20  requester_number_of_posts_on_raop_at_retrieval        4040 non-null   int32  \n",
      " 21  requester_number_of_subreddits_at_request             4040 non-null   int32  \n",
      " 22  requester_received_pizza                              4040 non-null   bool   \n",
      " 23  requester_subreddits_at_request                       4040 non-null   object \n",
      " 24  requester_upvotes_minus_downvotes_at_request          4040 non-null   int32  \n",
      " 25  requester_upvotes_minus_downvotes_at_retrieval        4040 non-null   int32  \n",
      " 26  requester_upvotes_plus_downvotes_at_request           4040 non-null   int32  \n",
      " 27  requester_upvotes_plus_downvotes_at_retrieval         4040 non-null   int32  \n",
      " 28  requester_user_flair                                  4040 non-null   object \n",
      " 29  requester_username                                    4040 non-null   object \n",
      " 30  unix_timestamp_of_request                             4040 non-null   int32  \n",
      " 31  unix_timestamp_of_request_utc                         4040 non-null   int32  \n",
      "dtypes: bool(2), float64(4), int32(17), int64(1), object(8)\n",
      "memory usage: 686.6+ KB\n"
     ]
    }
   ],
   "source": [
    "pizza_raw_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset has no missing values, so imputation processes will not be covered in this notebook, but should be considered in a full production-ready pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data leakage prevention\n",
    "\n",
    "Some features may lead to data leakage.\n",
    "One is directly linked to pizza donation, `giver_username_if_known`.\n",
    "Others may be since they aren't concerned about at_request/at_retrieval split-up, such as `requester_user_flair` *(requester badge obtention after receiving a pizza donation)*, `request_text` and `post_was_edited` *(some request posts are edited after getting a pizza donation)*.\n",
    "So, these features are removed from our project."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pizza_prevented_data = pizza_raw_data.loc[:, ~(pizza_raw_data\n",
    "                                               .columns\n",
    "                                               .isin([\"giver_username_if_known\",\n",
    "                                                      \"requester_user_flair\",\n",
    "                                                      \"request_text\",\n",
    "                                                      \"post_was_edited\"]))\n",
    "                       ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "target_name = 'requester_received_pizza'\n",
    "seed = 101\n",
    "X = pizza_prevented_data.copy()\n",
    "y = X.pop(target_name)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 4040 samples, we'll use 3232 of them to train the model.\n",
      "From 3232 requests, 795 led to a donation, which represents 24.6%.\n",
      "Thus, among 1026 days, 1 pizza was donate every 1.29 day.\n"
     ]
    }
   ],
   "source": [
    "dataset_period = (dt.strptime(\"29/09/2013\", \"%d/%m/%Y\") - dt.strptime(\"08/12/2010\", \"%d/%m/%Y\")).days\n",
    "\n",
    "print(f'''From our {pizza_raw_data.shape[0]} samples, we'll use {X_train.shape[0]} of them to train the model.\n",
    "From {len(y_train)} requests, {y_train.sum()} led to a donation, which represents {round(y_train.sum()/len(y_train), 3)*100}%.\n",
    "Thus, among {dataset_period} days, 1 pizza was donate every {round(dataset_period/y_train.sum(), 2)} day.''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One request out of four is therefore legitimate according to our statements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dissociate features at request from at retrieval\n",
    "\n",
    "In order to avoid data leakage, for example a request that had a donation could have a posteriori some upvotes boost, only features at request time are accounted according to the first objective to model legitimacy of a request."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "univariate_features = [\"request_id\",\n",
    "                       \"requester_username\",\n",
    "                       \"unix_timestamp_of_request_utc\", #non-utc timestamp is redundant and less convenient\n",
    "                       \"request_title\",\n",
    "                       \"request_text_edit_aware\"]\n",
    "\n",
    "at_request_features = []\n",
    "at_retrieval_features = []\n",
    "\n",
    "for selected_time, selected_features in {\"at_request\": at_request_features, \"at_retrieval\": at_retrieval_features}.items():\n",
    "    dataset_features = (X_train\n",
    "                        .filter(regex=f'.*{selected_time}$')\n",
    "                        .columns\n",
    "                        .tolist())\n",
    "    selected_features.extend(dataset_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train = X_train[univariate_features + at_request_features]\n",
    "#pizza_retrieval_data = X_train[univariate_features + at_retrieval_features]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 raw features can be used to predict legitimacy of a request.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.shape[1]} raw features can be used to predict legitimacy of a request.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       request_id requester_username  unix_timestamp_of_request_utc  \\\ncount        3232               3232                   3.232000e+03   \nunique       3232               3232                            NaN   \ntop      t3_m9dxg       mindfragment                            NaN   \nfreq            1                  1                            NaN   \nmean          NaN                NaN                   1.342692e+09   \nstd           NaN                NaN                   2.329957e+07   \nmin           NaN                NaN                   1.297723e+09   \n25%           NaN                NaN                   1.320189e+09   \n50%           NaN                NaN                   1.342561e+09   \n75%           NaN                NaN                   1.364035e+09   \nmax           NaN                NaN                   1.381523e+09   \n\n       request_title request_text_edit_aware  \\\ncount           3232                    3232   \nunique          3224                    3148   \ntop        [REQUEST]                           \nfreq               4                      81   \nmean             NaN                     NaN   \nstd              NaN                     NaN   \nmin              NaN                     NaN   \n25%              NaN                     NaN   \n50%              NaN                     NaN   \n75%              NaN                     NaN   \nmax              NaN                     NaN   \n\n        requester_account_age_in_days_at_request  \\\ncount                                3232.000000   \nunique                                       NaN   \ntop                                          NaN   \nfreq                                         NaN   \nmean                                  250.563901   \nstd                                   296.577877   \nmin                                     0.000000   \n25%                                     3.637118   \n50%                                   157.067170   \n75%                                   385.619852   \nmax                                  2521.263206   \n\n        requester_days_since_first_post_on_raop_at_request  \\\ncount                                         3232.000000    \nunique                                                NaN    \ntop                                                   NaN    \nfreq                                                  NaN    \nmean                                            16.177954    \nstd                                             68.784004    \nmin                                              0.000000    \n25%                                              0.000000    \n50%                                              0.000000    \n75%                                              0.000000    \nmax                                            785.457685    \n\n        requester_number_of_comments_at_request  \\\ncount                               3232.000000   \nunique                                      NaN   \ntop                                         NaN   \nfreq                                        NaN   \nmean                                 115.656869   \nstd                                  194.069195   \nmin                                    0.000000   \n25%                                    0.000000   \n50%                                   24.000000   \n75%                                  140.000000   \nmax                                  992.000000   \n\n        requester_number_of_comments_in_raop_at_request  \\\ncount                                       3232.000000   \nunique                                              NaN   \ntop                                                 NaN   \nfreq                                                NaN   \nmean                                           0.673886   \nstd                                            3.484070   \nmin                                            0.000000   \n25%                                            0.000000   \n50%                                            0.000000   \n75%                                            0.000000   \nmax                                           88.000000   \n\n        requester_number_of_posts_at_request  \\\ncount                            3232.000000   \nunique                                   NaN   \ntop                                      NaN   \nfreq                                     NaN   \nmean                               21.008045   \nstd                                48.624350   \nmin                                 0.000000   \n25%                                 0.000000   \n50%                                 5.000000   \n75%                                22.000000   \nmax                               867.000000   \n\n        requester_number_of_posts_on_raop_at_request  \\\ncount                                    3232.000000   \nunique                                           NaN   \ntop                                              NaN   \nfreq                                             NaN   \nmean                                        0.068379   \nstd                                         0.338350   \nmin                                         0.000000   \n25%                                         0.000000   \n50%                                         0.000000   \n75%                                         0.000000   \nmax                                         5.000000   \n\n        requester_number_of_subreddits_at_request  \\\ncount                                 3232.000000   \nunique                                        NaN   \ntop                                           NaN   \nfreq                                          NaN   \nmean                                    18.022587   \nstd                                     21.701225   \nmin                                      0.000000   \n25%                                      1.000000   \n50%                                     11.000000   \n75%                                     27.000000   \nmax                                    186.000000   \n\n       requester_subreddits_at_request  \\\ncount                             3232   \nunique                            2399   \ntop                                 []   \nfreq                               585   \nmean                               NaN   \nstd                                NaN   \nmin                                NaN   \n25%                                NaN   \n50%                                NaN   \n75%                                NaN   \nmax                                NaN   \n\n        requester_upvotes_minus_downvotes_at_request  \\\ncount                                    3232.000000   \nunique                                           NaN   \ntop                                              NaN   \nfreq                                             NaN   \nmean                                     1144.773205   \nstd                                      3712.847322   \nmin                                      -173.000000   \n25%                                         3.000000   \n50%                                       177.000000   \n75%                                      1154.000000   \nmax                                    155010.000000   \n\n        requester_upvotes_plus_downvotes_at_request  \ncount                                  3.232000e+03  \nunique                                          NaN  \ntop                                             NaN  \nfreq                                            NaN  \nmean                                   3.636832e+03  \nstd                                    2.501816e+04  \nmin                                    0.000000e+00  \n25%                                    9.000000e+00  \n50%                                    3.540000e+02  \n75%                                    2.287750e+03  \nmax                                    1.286864e+06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>request_id</th>\n      <th>requester_username</th>\n      <th>unix_timestamp_of_request_utc</th>\n      <th>request_title</th>\n      <th>request_text_edit_aware</th>\n      <th>requester_account_age_in_days_at_request</th>\n      <th>requester_days_since_first_post_on_raop_at_request</th>\n      <th>requester_number_of_comments_at_request</th>\n      <th>requester_number_of_comments_in_raop_at_request</th>\n      <th>requester_number_of_posts_at_request</th>\n      <th>requester_number_of_posts_on_raop_at_request</th>\n      <th>requester_number_of_subreddits_at_request</th>\n      <th>requester_subreddits_at_request</th>\n      <th>requester_upvotes_minus_downvotes_at_request</th>\n      <th>requester_upvotes_plus_downvotes_at_request</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3232</td>\n      <td>3232</td>\n      <td>3.232000e+03</td>\n      <td>3232</td>\n      <td>3232</td>\n      <td>3232.000000</td>\n      <td>3232.000000</td>\n      <td>3232.000000</td>\n      <td>3232.000000</td>\n      <td>3232.000000</td>\n      <td>3232.000000</td>\n      <td>3232.000000</td>\n      <td>3232</td>\n      <td>3232.000000</td>\n      <td>3.232000e+03</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3232</td>\n      <td>3232</td>\n      <td>NaN</td>\n      <td>3224</td>\n      <td>3148</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2399</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>t3_m9dxg</td>\n      <td>mindfragment</td>\n      <td>NaN</td>\n      <td>[REQUEST]</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>81</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>585</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.342692e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>250.563901</td>\n      <td>16.177954</td>\n      <td>115.656869</td>\n      <td>0.673886</td>\n      <td>21.008045</td>\n      <td>0.068379</td>\n      <td>18.022587</td>\n      <td>NaN</td>\n      <td>1144.773205</td>\n      <td>3.636832e+03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.329957e+07</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>296.577877</td>\n      <td>68.784004</td>\n      <td>194.069195</td>\n      <td>3.484070</td>\n      <td>48.624350</td>\n      <td>0.338350</td>\n      <td>21.701225</td>\n      <td>NaN</td>\n      <td>3712.847322</td>\n      <td>2.501816e+04</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.297723e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>-173.000000</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.320189e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.637118</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>9.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.342561e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>157.067170</td>\n      <td>0.000000</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>11.000000</td>\n      <td>NaN</td>\n      <td>177.000000</td>\n      <td>3.540000e+02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.364035e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>385.619852</td>\n      <td>0.000000</td>\n      <td>140.000000</td>\n      <td>0.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>27.000000</td>\n      <td>NaN</td>\n      <td>1154.000000</td>\n      <td>2.287750e+03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.381523e+09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2521.263206</td>\n      <td>785.457685</td>\n      <td>992.000000</td>\n      <td>88.000000</td>\n      <td>867.000000</td>\n      <td>5.000000</td>\n      <td>186.000000</td>\n      <td>NaN</td>\n      <td>155010.000000</td>\n      <td>1.286864e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe(include=\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data exploration\n",
    "## Let's start first with non-textual data ...\n",
    "\n",
    "In order to have ground level refrence, let's start with a very basic modelisation with underperforming results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(exclude=[\"object\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3232 entries, 3418 to 813\n",
      "Data columns (total 10 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   unix_timestamp_of_request_utc                       3232 non-null   int32  \n",
      " 1   requester_account_age_in_days_at_request            3232 non-null   float64\n",
      " 2   requester_days_since_first_post_on_raop_at_request  3232 non-null   float64\n",
      " 3   requester_number_of_comments_at_request             3232 non-null   int32  \n",
      " 4   requester_number_of_comments_in_raop_at_request     3232 non-null   int32  \n",
      " 5   requester_number_of_posts_at_request                3232 non-null   int32  \n",
      " 6   requester_number_of_posts_on_raop_at_request        3232 non-null   int32  \n",
      " 7   requester_number_of_subreddits_at_request           3232 non-null   int32  \n",
      " 8   requester_upvotes_minus_downvotes_at_request        3232 non-null   int32  \n",
      " 9   requester_upvotes_plus_downvotes_at_request         3232 non-null   int32  \n",
      "dtypes: float64(2), int32(8)\n",
      "memory usage: 176.8 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_num.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature engineering\n",
    "\n",
    "Votes give great insights with the sum related to visibility and difference related to consensus/polarisation. However, the 2 variables here are absolute and a relative one is missing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "num = 'requester_upvotes_minus_downvotes_at_request'\n",
    "den = 'requester_upvotes_plus_downvotes_at_request'\n",
    "X_train_num['requester_relative_consensual_votes_at_request'] = X_train_num[[num, den]].apply(lambda row: row.iloc[1] and row.iloc[0] / row.iloc[1] or 0,\n",
    "                                                                                              axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature importances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    mi_results = mutual_info_classif(X, y, random_state=seed)\n",
    "    mi_results = pd.Series(mi_results, name=\"MI Scores\", index=X.columns)\n",
    "    return mi_results\n",
    "\n",
    "def make_f_oneway_scores(X, y):\n",
    "    grp_anova = X.groupby(y)\n",
    "\n",
    "    f_values = []\n",
    "    for feat in X.columns:\n",
    "        s, p = f_oneway(grp_anova.get_group(0)[feat],\n",
    "                        grp_anova.get_group(1)[feat])\n",
    "        s = round(s, 4)\n",
    "        p = round(p, 4)\n",
    "        f_values.append((s, p))\n",
    "\n",
    "    f_scores = pd.Series(f_values, name=\"F_oneway Scores\", index=X.columns)\n",
    "    return f_scores\n",
    "\n",
    "def make_corr_scores(X, y):\n",
    "    return X.corrwith(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    Mutual Info  Correlation  \\\nunix_timestamp_of_request_utc                          0.021659    -0.109957   \nrequester_account_age_in_days_at_request               0.005067     0.046025   \nrequester_days_since_first_post_on_raop_at_request     0.010643     0.113513   \nrequester_number_of_comments_at_request                0.000000     0.022811   \nrequester_number_of_comments_in_raop_at_request        0.002449     0.136583   \nrequester_number_of_posts_at_request                   0.003030     0.008033   \nrequester_number_of_posts_on_raop_at_request           0.006741     0.145767   \nrequester_number_of_subreddits_at_request              0.012759     0.024470   \nrequester_upvotes_minus_downvotes_at_request           0.000000     0.032900   \nrequester_upvotes_plus_downvotes_at_request            0.002027     0.032593   \nrequester_relative_consensual_votes_at_request         0.005138     0.077609   \n\n                                                      F_oneway (s,p)  \nunix_timestamp_of_request_utc                         (39.5304, 0.0)  \nrequester_account_age_in_days_at_request            (6.8567, 0.0089)  \nrequester_days_since_first_post_on_raop_at_request    (42.1623, 0.0)  \nrequester_number_of_comments_at_request             (1.6815, 0.1948)  \nrequester_number_of_comments_in_raop_at_request       (61.4012, 0.0)  \nrequester_number_of_posts_at_request                 (0.2084, 0.648)  \nrequester_number_of_posts_on_raop_at_request          (70.1211, 0.0)  \nrequester_number_of_subreddits_at_request           (1.9353, 0.1643)  \nrequester_upvotes_minus_downvotes_at_request        (3.4999, 0.0615)  \nrequester_upvotes_plus_downvotes_at_request          (3.435, 0.0639)  \nrequester_relative_consensual_votes_at_request        (19.5727, 0.0)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mutual Info</th>\n      <th>Correlation</th>\n      <th>F_oneway (s,p)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>unix_timestamp_of_request_utc</th>\n      <td>0.021659</td>\n      <td>-0.109957</td>\n      <td>(39.5304, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_account_age_in_days_at_request</th>\n      <td>0.005067</td>\n      <td>0.046025</td>\n      <td>(6.8567, 0.0089)</td>\n    </tr>\n    <tr>\n      <th>requester_days_since_first_post_on_raop_at_request</th>\n      <td>0.010643</td>\n      <td>0.113513</td>\n      <td>(42.1623, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_comments_at_request</th>\n      <td>0.000000</td>\n      <td>0.022811</td>\n      <td>(1.6815, 0.1948)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_comments_in_raop_at_request</th>\n      <td>0.002449</td>\n      <td>0.136583</td>\n      <td>(61.4012, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_posts_at_request</th>\n      <td>0.003030</td>\n      <td>0.008033</td>\n      <td>(0.2084, 0.648)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_posts_on_raop_at_request</th>\n      <td>0.006741</td>\n      <td>0.145767</td>\n      <td>(70.1211, 0.0)</td>\n    </tr>\n    <tr>\n      <th>requester_number_of_subreddits_at_request</th>\n      <td>0.012759</td>\n      <td>0.024470</td>\n      <td>(1.9353, 0.1643)</td>\n    </tr>\n    <tr>\n      <th>requester_upvotes_minus_downvotes_at_request</th>\n      <td>0.000000</td>\n      <td>0.032900</td>\n      <td>(3.4999, 0.0615)</td>\n    </tr>\n    <tr>\n      <th>requester_upvotes_plus_downvotes_at_request</th>\n      <td>0.002027</td>\n      <td>0.032593</td>\n      <td>(3.435, 0.0639)</td>\n    </tr>\n    <tr>\n      <th>requester_relative_consensual_votes_at_request</th>\n      <td>0.005138</td>\n      <td>0.077609</td>\n      <td>(19.5727, 0.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores = make_mi_scores(X_train_num, y_train)\n",
    "f_oneway_scores = make_f_oneway_scores(X_train_num, y_train)\n",
    "corr_scores = make_corr_scores(X_train_num, y_train)\n",
    "\n",
    "pd_info = pd.concat([mi_scores, corr_scores, f_oneway_scores], axis='columns')\n",
    "pd_info.columns =[\"Mutual Info\", \"Correlation\", \"F_oneway (s,p)\"]\n",
    "pd_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that almost all features have some importance, with `requester_number_of_posts_at_request` being the least important of them.\n",
    "The previous created `requester_relative_consensual_votes_at_request` feature looks like a good new addition, and beating its creation features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelisation\n",
    "\n",
    "Now that we're at the modelisation step, there is one important question, which is what metric to use.\n",
    "The real subquestion is, in terms of business, what is more prolific and harmless in the fact of donate to a mostly illegitimate request or on contrary not donating to a legitimate request.\n",
    "The first, a false positive, harms the branding image and financial cost, the other, a false negative, harms notoriety.\n",
    "But most of all, as described earlier, this algorithm doesn't lead directly to donation. It outputs only so-called legitimacy, which will take a big place in the donation decision but still can be hold back on a decision algorithm.\n",
    "With that in mind, the main goal should be to minimize false positives with a metric such as precision, as long as false negatives are not numerous."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def create_impute_preproc(numerical_features, scaler_method = None):\n",
    "    steps = [('scaler_method', scaler_method)]\n",
    "    scaler_transformer = Pipeline(steps)\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('scaler_transformer', scaler_transformer, numerical_features)\n",
    "        ], remainder='drop')\n",
    "\n",
    "    # Model pipeline\n",
    "    steps = [('preproc', preprocessor)]\n",
    "    proc_pipe = Pipeline(steps)\n",
    "\n",
    "    return proc_pipe\n",
    "\n",
    "def create_pipeline(train_set, preproc, estimator, model_name, grid_strat, hyperparameters, n_folds,\n",
    "                    eval_metric='precision', verbosity=3, n_jobs=10):\n",
    "    X, y = train_set\n",
    "    X_preproc = preproc.fit_transform(X)\n",
    "    X_preproc = pd.DataFrame(X_preproc, columns=X.columns, index=X.index)\n",
    "\n",
    "    # Model pipeline\n",
    "    steps = [(model_name, estimator)]\n",
    "    model_pipe = Pipeline(steps)\n",
    "\n",
    "    # Grid Search\n",
    "    cv = grid_strat(model_pipe,\n",
    "                    param_grid=hyperparameters,\n",
    "                    cv=n_folds,\n",
    "                    scoring=eval_metric,\n",
    "                    n_jobs=n_jobs,\n",
    "                    verbose=verbosity,\n",
    "                    random_state=seed)\n",
    "\n",
    "    grid_model = cv.fit(X_preproc, y)\n",
    "\n",
    "    return grid_model\n",
    "\n",
    "def print_pipe_results(train_set, model):\n",
    "    X, y = train_set\n",
    "\n",
    "    yhat = model.best_estimator_.predict(X)\n",
    "    print(f'In-samples resutls:\\n {classification_report(y, yhat)}')\n",
    "    print()\n",
    "    print(f'''Confusion matrix:\n",
    "{pd.DataFrame(confusion_matrix(y, yhat, normalize='all'),\n",
    "              columns=[\"PredNeg\", \"PredPos\"],\n",
    "              index=[\"Neg\", \"Pos\"])}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 39\n",
      "max_resources_: 3232\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 128\n",
      "n_resources: 39\n",
      "Fitting 4 folds for each of 128 candidates, totalling 512 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 43\n",
      "n_resources: 117\n",
      "Fitting 4 folds for each of 43 candidates, totalling 172 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 15\n",
      "n_resources: 351\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 5\n",
      "n_resources: 1053\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 3159\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim van Eersel\\Python_Projects\\kaggle\\Random Acts of Pizza - CybelAngel\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',\n",
    "                           random_state=seed)\n",
    "\n",
    "model_name = 'logreg'\n",
    "\n",
    "parameters = {f'{model_name}__C': np.logspace(0.7, 1.3, 4),\n",
    "              f'{model_name}__fit_intercept': (True, False),\n",
    "              f'{model_name}__class_weight': (None, 'balanced'),\n",
    "              f'{model_name}__penalty': ['l1', 'l2'],\n",
    "              f'{model_name}__max_iter': np.linspace(20, 2000, 4).astype(int)\n",
    "              }\n",
    "\n",
    "logreg_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                                preproc=create_impute_preproc(X_train_num.columns, scaler_method=None),\n",
    "                                estimator = model,\n",
    "                                model_name = model_name,\n",
    "                                grid_strat=HalvingGridSearchCV,\n",
    "                                hyperparameters = parameters,\n",
    "                                n_folds = 4,\n",
    "                                eval_metric='precision',\n",
    "                                verbosity=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.68      0.74      2437\n",
      "        True       0.35      0.54      0.43       795\n",
      "\n",
      "    accuracy                           0.64      3232\n",
      "   macro avg       0.59      0.61      0.58      3232\n",
      "weighted avg       0.70      0.64      0.66      3232\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.512686  0.241337\n",
      "Pos  0.113861  0.132116\n"
     ]
    }
   ],
   "source": [
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   model = logreg_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression doesn't offer great performance whatever the tuning.\n",
    "There is an hypertune way to improve precision up to 65% but decrease catastrophically the recall, so overall it's worse than the current state."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 1\n",
      "min_resources_: 3232\n",
      "max_resources_: 3232\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 3232\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "model_name = 'gaus_nb'\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "gaussnb_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                                 preproc=create_impute_preproc(X_train_num.columns, scaler_method=None),\n",
    "                                 estimator = model,\n",
    "                                 model_name = model_name,\n",
    "                                 grid_strat=HalvingGridSearchCV,\n",
    "                                 hyperparameters = parameters,\n",
    "                                 n_folds = 4,\n",
    "                                 eval_metric='precision',\n",
    "                                 verbosity=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.97      0.85      2437\n",
      "        True       0.27      0.03      0.05       795\n",
      "\n",
      "    accuracy                           0.74      3232\n",
      "   macro avg       0.51      0.50      0.45      3232\n",
      "weighted avg       0.63      0.74      0.65      3232\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.735149  0.018874\n",
      "Pos  0.239171  0.006807\n"
     ]
    }
   ],
   "source": [
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   model = gaussnb_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 359\n",
      "max_resources_: 3232\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 16\n",
      "n_resources: 359\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 6\n",
      "n_resources: 1077\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 2\n",
      "n_resources: 3231\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=seed, n_jobs=10)\n",
    "\n",
    "model_name = 'rf'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(10, 300, 4).astype(int),\n",
    "              f'{model_name}__max_depth': np.linspace(2, 9, 4).astype(int)}\n",
    "\n",
    "rf_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                            preproc=create_impute_preproc(X_train_num.columns, scaler_method=None),\n",
    "                            estimator = model,\n",
    "                            model_name = model_name,\n",
    "                            grid_strat=HalvingGridSearchCV,\n",
    "                            hyperparameters = parameters,\n",
    "                            n_folds = 4,\n",
    "                            eval_metric='f1', #better overall, little downgrade on precision high boost on recall\n",
    "                            verbosity=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      1.00      0.89      2437\n",
      "        True       0.95      0.28      0.44       795\n",
      "\n",
      "    accuracy                           0.82      3232\n",
      "   macro avg       0.88      0.64      0.67      3232\n",
      "weighted avg       0.85      0.82      0.78      3232\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.750619  0.003403\n",
      "Pos  0.176052  0.069926\n"
     ]
    }
   ],
   "source": [
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   model = rf_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGBoost Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 119\n",
      "max_resources_: 3232\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 72\n",
      "n_resources: 119\n",
      "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 24\n",
      "n_resources: 357\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 8\n",
      "n_resources: 1071\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 3213\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=seed,\n",
    "                          objective='binary:logistic',\n",
    "                          eval_metric=precision_score,\n",
    "                          tree_method='gpu_hist')\n",
    "\n",
    "model_name = 'xgb_cl'\n",
    "\n",
    "parameters = {f'{model_name}__n_estimators': np.linspace(20, 500, 3).astype(int),\n",
    "              f'{model_name}__learning_rate': np.logspace(-1, 0, 2),\n",
    "              f'{model_name}__max_depth': np.linspace(2, 9, 3).astype(int),\n",
    "              f'{model_name}__booster': ['gbtree'],\n",
    "              f'{model_name}__colsample_bytree': np.logspace(-0.7, 0, 2),\n",
    "              f'{model_name}__subsample': np.logspace(-0.7, 0, 2)\n",
    "             }\n",
    "\n",
    "xgb_gridCV = create_pipeline(train_set = [X_train_num, y_train],\n",
    "                             preproc=create_impute_preproc(X_train_num.columns, scaler_method=None),\n",
    "                             estimator = model,\n",
    "                             model_name = model_name,\n",
    "                             grid_strat=HalvingGridSearchCV,\n",
    "                             hyperparameters = parameters,\n",
    "                             n_folds = 4,\n",
    "                             eval_metric='precision', # f1 is bad -> 0.47 precision / 0.46 recall\n",
    "                             verbosity=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-samples resutls:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.99      0.88      2437\n",
      "        True       0.83      0.20      0.32       795\n",
      "\n",
      "    accuracy                           0.79      3232\n",
      "   macro avg       0.81      0.59      0.60      3232\n",
      "weighted avg       0.80      0.79      0.74      3232\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.744121  0.009901\n",
      "Pos  0.197092  0.048886\n"
     ]
    }
   ],
   "source": [
    "print_pipe_results(train_set = [X_train_num, y_train],\n",
    "                   model = xgb_gridCV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion\n",
    "\n",
    "After model comparison and light hypertunings, results aren't very concluding. It was expected with only these variables *(backed up by the features importance part)*.\n",
    "Something quite surprising nonetheless is that CART can achieve very high precision performance but at the cost of a diying recall.\n",
    "Let's move to textual modelisation to pump up our game."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ... and get the final word."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "X_train_text = X_train.select_dtypes(include=[\"object\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3232 entries, 3418 to 813\n",
      "Data columns (total 5 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   request_id                       3232 non-null   object\n",
      " 1   requester_username               3232 non-null   object\n",
      " 2   request_title                    3232 non-null   object\n",
      " 3   request_text_edit_aware          3232 non-null   object\n",
      " 4   requester_subreddits_at_request  3232 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 151.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_text.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only `request_title` and `request_text_edit_aware` are NLP oriented features, so it'll be the main focus."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
