{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4a0988-8c94-48b5-a6d5-9f7df3b6ae25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Random Acts of Pizza\n",
    "\n",
    "![Pizza Badges](../reports/images/pizzas.png)\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur**: Akim van Eersel  \n",
    "**Date**: 2022-12-30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd58b02-dcdd-4ab4-b575-98077576bc3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Predire la donation de pizza à travers un subreddit dédié\n",
    "\n",
    "## Subreddit RAOP\n",
    "\n",
    "Le r/RAOP permet d'obtenir des données sur des demandes faites par des internautes afin de potentiellement se voir offrir une pizza.  \n",
    "Ces données se composent tout ce qui se raccorde à la demande (contenu et métadonnées) ainsi qu'à certaines informations du profil Reddit du demandeur.\n",
    "\n",
    "## Hypothèses\n",
    "\n",
    "**Localisation** : d'un point de vue business, l'utilisation de données provenant de Reddit ne doit pas influer sur la population ciblée.  \n",
    "**Décalage temporel** : les données datent d'il y a 9 ans et se sont écoulées sur une période de 3 ans. Le fait de faire une donation et ce relevant d'une pizza est jugé intemporel socialement et économiquement.  \n",
    "**Sagesse des foules** : la donation d'un-e individu à un-e autre est déterminée comme étant une décision impartielement légitime avec un petit delta du au procédé global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ded10e-a5ac-4732-95da-e04deabe1201",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Enjeux business\n",
    "\n",
    "L'idée de pouvoir prédire la donation de pizza est projeté sur une étude de cas où une chaîne de pizza cherche à mettre en place un procédé similaire pour gagner entre autres en notoriété de marque.  \n",
    "Les enjeux sont alors :  \n",
    "1. d'obtenir un modèle pouvant prédire la légitimité d'une demande par un-e individu au moment de la demande,  \n",
    "2. de pouvoir valider cette prédiction a posteriori pour appuyer en aval la décision d'offrir une pizza de la part du restaurant.\n",
    "\n",
    "### Décision applicative\n",
    "\n",
    "Le modèle décrit ne devrait pas être l'unique décisionnaire sur la décision finale de donation, surtout si ce dernier n'est pas ultra-performant. Celui-ci devrait être réutilisé comme une des entrées pour un second algorithme de décision, et en imaginant facilement d'autre variables liées aux implications business et de supply chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386b1692-9906-4022-ae22-828c15fb7ab1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\AKIMVA~1\\AppData\\Local\\Temp/ipykernel_20164/2349701167.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensemble\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mRandomForestClassifier\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnaive_bayes\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mMultinomialNB\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGaussianNB\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mxgboost\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mxgb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcorpus\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mstopwords\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from scipy.stats import f_oneway\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2, SelectKBest\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecbe8c-0c5e-4137-a89a-678e2a7f334b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Présentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de8770c-ce1f-4bcc-9088-6b197b106aff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 4040 samples, we'll use 3636 of them to train the model.\n",
      "From 3636 requests, 895 led to a donation, which represents 24.6%.\n",
      "Thus, among 1026 days, 1 pizza was donate every 1.15 day.\n"
     ]
    }
   ],
   "source": [
    "pizza_raw_data = pd.read_json('../data/pizza_data.json',\n",
    "                              dtype={\"giver_username_if_known\": str,\n",
    "                                     \"number_of_upvotes_of_request_at_retrieval\": int,\n",
    "                                     \"post_was_edited\": bool,\n",
    "                                     \"request_id\": str,\n",
    "                                     \"request_number_of_comments_at_retrieval\": int,\n",
    "                                     \"request_text\": str,\n",
    "                                     \"request_text_edit_aware\": str,\n",
    "                                     \"request_title\": str,\n",
    "                                     \"requester_account_age_in_days_at_request\": float,\n",
    "                                     \"requester_account_age_in_days_at_retrieval\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_request\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_retrieval\": float,\n",
    "                                     \"requester_number_of_comments_at_request\": int,\n",
    "                                     \"requester_number_of_comments_at_retrieval\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_request\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_at_request\": int,\n",
    "                                     \"requester_number_of_posts_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_request\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_subreddits_at_request\": int,\n",
    "                                     \"requester_received_pizza\": bool,\n",
    "                                     \"requester_subreddits_at_request\": list,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_user_flair\": str,\n",
    "                                     \"requester_username\": str,\n",
    "                                     \"unix_timestamp_of_request\": int,\n",
    "                                     \"unix_timestamp_of_request_utc\": int})\n",
    "\n",
    "pizza_prevented_data = pizza_raw_data.loc[:, ~(pizza_raw_data\n",
    "                                               .columns\n",
    "                                               .isin([\"giver_username_if_known\",\n",
    "                                                      \"requester_user_flair\",\n",
    "                                                      \"request_text\",\n",
    "                                                      \"post_was_edited\"]))\n",
    "                       ]\n",
    "\n",
    "dataset_period = (dt.strptime(\"29/09/2013\", \"%d/%m/%Y\") - dt.strptime(\"08/12/2010\", \"%d/%m/%Y\")).days\n",
    "\n",
    "target_name = 'requester_received_pizza'\n",
    "seed = 101\n",
    "X = pizza_prevented_data.copy()\n",
    "y = X.pop(target_name)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=seed, stratify=y_test)\n",
    "\n",
    "print(f'''From our {pizza_raw_data.shape[0]} samples, we'll use {X_train.shape[0]} of them to train the model.\n",
    "From {len(y_train)} requests, {y_train.sum()} led to a donation, which represents {round(y_train.sum()/len(y_train), 3)*100}%.\n",
    "Thus, among {dataset_period} days, 1 pizza was donate every {round(dataset_period/y_train.sum(), 2)} day.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
