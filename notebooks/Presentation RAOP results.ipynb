{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4a0988-8c94-48b5-a6d5-9f7df3b6ae25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Random Acts of Pizza\n",
    "\n",
    "![Pizza Badges](https://storage.googleapis.com/kaggle-competitions/kaggle/3949/media/pizzas.png)\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur**: Akim van Eersel  \n",
    "**Date**: 2022-12-30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd58b02-dcdd-4ab4-b575-98077576bc3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Predire la donation de pizza à travers un subreddit dédié\n",
    "\n",
    "### Subreddit RAOP\n",
    "\n",
    "Le r/RAOP permet d'obtenir des données sur des demandes faites par des internautes, afin de potentiellement se voir offrir une pizza.  \n",
    "Ces données se rapportent à la demande *(contenu et métadonnées)* ainsi qu'à certaines informations du profil Reddit du demandeur.\n",
    "\n",
    "### Hypothèses\n",
    "\n",
    "**Localisation** : d'un point de vue business, l'utilisation de données provenant de Reddit ne doit pas influer sur la population ciblée.  \n",
    "**Décalage temporel** : les données datent d'il y a 9 ans et se sont écoulées sur une période de 3 ans. Le fait de faire une donation et qu'il s'aggisse d'une pizza est jugé socialement et économiquement intemporel.  \n",
    "**Sagesse des foules** : la donation d'un-e individu à un-e autre est déterminée comme étant impartialement légitime *(petit delta dû au procédé global)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ded10e-a5ac-4732-95da-e04deabe1201",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Enjeux business\n",
    "\n",
    "Pouvoir prédire la donation de pizza est projeté sur une étude de cas, où une chaîne de pizzeria cherche à mettre en place un procédé similaire, pour gagner entre autres en notoriété de marque.  \n",
    "L'enjeu est d'obtenir un modèle prédisant la légitimité d'une demande par un-e individu au moment de celle-ci.\n",
    "\n",
    "#### Décision applicative\n",
    "\n",
    "Ce modèle ne devrait pas être l'unique décisionnaire de donation, surtout si ce dernier n'est pas ultra-performant.  \n",
    "Celui-ci devrait être réutilisé en entrée d'un second algorithme de décision, face à d'autres variables liées aux implications business *(supply chain, etc)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386b1692-9906-4022-ae22-828c15fb7ab1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from scipy.stats import f_oneway\n",
    "import joblib\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2, SelectKBest\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecbe8c-0c5e-4137-a89a-678e2a7f334b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Présentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de8770c-ce1f-4bcc-9088-6b197b106aff",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pizza_raw_data = pd.read_json('../data/pizza_data.json',\n",
    "                              dtype={\"giver_username_if_known\": str,\n",
    "                                     \"number_of_upvotes_of_request_at_retrieval\": int,\n",
    "                                     \"post_was_edited\": bool,\n",
    "                                     \"request_id\": str,\n",
    "                                     \"request_number_of_comments_at_retrieval\": int,\n",
    "                                     \"request_text\": str,\n",
    "                                     \"request_text_edit_aware\": str,\n",
    "                                     \"request_title\": str,\n",
    "                                     \"requester_account_age_in_days_at_request\": float,\n",
    "                                     \"requester_account_age_in_days_at_retrieval\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_request\": float,\n",
    "                                     \"requester_days_since_first_post_on_raop_at_retrieval\": float,\n",
    "                                     \"requester_number_of_comments_at_request\": int,\n",
    "                                     \"requester_number_of_comments_at_retrieval\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_request\": int,\n",
    "                                     \"requester_number_of_comments_in_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_at_request\": int,\n",
    "                                     \"requester_number_of_posts_at_retrieval\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_request\": int,\n",
    "                                     \"requester_number_of_posts_on_raop_at_retrieval\": int,\n",
    "                                     \"requester_number_of_subreddits_at_request\": int,\n",
    "                                     \"requester_received_pizza\": bool,\n",
    "                                     \"requester_subreddits_at_request\": list,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_minus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_request\": int,\n",
    "                                     \"requester_upvotes_plus_downvotes_at_retrieval\": int,\n",
    "                                     \"requester_user_flair\": str,\n",
    "                                     \"requester_username\": str,\n",
    "                                     \"unix_timestamp_of_request\": int,\n",
    "                                     \"unix_timestamp_of_request_utc\": int})\n",
    "\n",
    "pizza_prevented_data = pizza_raw_data.loc[:, ~(pizza_raw_data\n",
    "                                               .columns\n",
    "                                               .isin([\"giver_username_if_known\",\n",
    "                                                      \"requester_user_flair\",\n",
    "                                                      \"request_text\",\n",
    "                                                      \"post_was_edited\"]))\n",
    "                       ]\n",
    "\n",
    "dataset_period = (dt.strptime(\"29/09/2013\", \"%d/%m/%Y\") - dt.strptime(\"08/12/2010\", \"%d/%m/%Y\")).days\n",
    "\n",
    "target_name = 'requester_received_pizza'\n",
    "seed = 101\n",
    "X = pizza_prevented_data.copy()\n",
    "y = X.pop(target_name)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=seed, stratify=y_test)\n",
    "\n",
    "\n",
    "univariate_features = [\"unix_timestamp_of_request_utc\", #non-utc timestamp is redundant and less convenient\n",
    "                       \"request_title\",\n",
    "                       \"request_text_edit_aware\"]\n",
    "\n",
    "at_request_features = []\n",
    "at_retrieval_features = []\n",
    "\n",
    "for selected_time, selected_features in {\"at_request\": at_request_features, \"at_retrieval\": at_retrieval_features}.items():\n",
    "    dataset_features = (X_train\n",
    "                        .filter(regex=f'.*{selected_time}$')\n",
    "                        .columns\n",
    "                        .tolist())\n",
    "    selected_features.extend(dataset_features)\n",
    "\n",
    "pizza_retrieval_data = X_train[univariate_features + at_retrieval_features]\n",
    "X_train = X_train[univariate_features + at_request_features]\n",
    "\n",
    "wrapup_data_prez = f'''Le dataset est composé de {pizza_raw_data.shape[0]} observations, l'entrainement est fait sur 90% de l'ensemble, à savoir {X_train.shape[0]} observations.\n",
    "Parmi les {len(y)} requêtes, {y.sum()} ont mené à une donation, ce qui représente {round(y.sum()/len(y), 3)*100}%.\n",
    "Parmi la période de {dataset_period} jours, 1 pizza a été donné tous les {round(dataset_period/y_train.sum(), 2)} jour.\n",
    "\n",
    "Au sein de ce dataset, il existe {pizza_prevented_data.shape[1]} variables, dont {pizza_prevented_data.select_dtypes(exclude=['object']).shape[1]} non textuelles et {pizza_prevented_data.select_dtypes(include=['object']).shape[1]} textuelles.\n",
    "Pour la modélisation seulement {len(univariate_features + at_request_features)} de ces variables seront utilisées.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73398e4e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset est composé de 4040 observations, l'entrainement est fait sur 90% de l'ensemble, à savoir 3636 observations.\n",
      "Parmi les 4040 requêtes, 994 ont mené à une donations, ce qui représente 24.6%.\n",
      "Parmi la période de 1026 jours, 1 pizza a été donné tous les 1.15 jour.\n",
      "\n",
      "Au sein de ce dataset, il existe 28 variables, dont 23 non textuelles et 5 textuelles.\n",
      "Pour la modélisation seulement 13 de ces variables seront utilisées.\n"
     ]
    }
   ],
   "source": [
    "print(wrapup_data_prez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f4670d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_relative_votes(df, num, den, suffix=\"request\"):\n",
    "    math_fct = lambda row: row.iloc[1] and row.iloc[0] / row.iloc[1] or 0\n",
    "    df[f'requester_relative_consensual_votes_at_{suffix}'] = df.copy()[[num, den]].apply(math_fct, axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "diff_votes = 'requester_upvotes_minus_downvotes_at_request'\n",
    "sum_votes = 'requester_upvotes_plus_downvotes_at_request'\n",
    "\n",
    "def add_text_length(df):\n",
    "    post_feat = 'request_text_edit_aware'\n",
    "    df[[f'{post_feat}_len']] = df.copy()[[post_feat]].apply(len)\n",
    "\n",
    "    return df\n",
    "\n",
    "X_test_lotr = add_text_length(X_test)\n",
    "X_test_lotr = add_relative_votes(X_test_lotr, num=diff_votes, den=sum_votes)\n",
    "\n",
    "xgb_lotr_model = joblib.load(f'../models/xgb_nlp_f1_pipeline.joblib')\n",
    "\n",
    "def print_pipe_results(data_set, model):\n",
    "    X_set, y_set = data_set\n",
    "    yhat = model.predict(X_set)\n",
    "    print(f'Out-of-samples classification report:\\n\\n {classification_report(y_set, yhat)}')\n",
    "    print()\n",
    "    print(f'''Confusion matrix:\n",
    "{pd.DataFrame(confusion_matrix(y_set, yhat, normalize='all'),\n",
    "              columns=[\"PredNeg\", \"PredPos\"],\n",
    "              index=[\"Neg\", \"Pos\"])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6848e99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Modelisation\n",
    "\n",
    "### Métrique d'évaluation\n",
    "\n",
    "La precision est la métrique d'évaluation choisie, en raison de son implication d'un point de vue business.  \n",
    "En effet, celle-ci cherchant à diminuer les faux positifs, on se prémunit ainsi des demandes labellisées comme étant légitimes mais erronées, évitant de procéder aux dons impactant l'aspect financier.  \n",
    "\n",
    "Toute chose étant égale par ailleurs, il est nécessaire de garder un oeil sur le nombre de faux négatifs afin d'avoir une certaine balance acceptable si possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3158c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Modèle\n",
    "\n",
    "Le modèle retenu fait partie de la famille des ensembles d'arbres de décision, une des versions les plus évolués, à savoir xgboost.\n",
    "\n",
    "Pour tirer au mieux des capacités de ce modèle, une étape de preprocessing est nécessaire dans le cas de données textuelles.\n",
    "Cette dernière se compose d'un workflow usuel en NLP :\n",
    "1. Création d'un BOW, incluant les 2-grams, avec un tokenizer de mots provenant de la librairie NLTK, en gardant uniquement les comptes de 4 ou plus.\n",
    "2. Transformation de cette matrice de décompte en une matrice TF-IDF pour obtenir les occurrences les plus pertinentes.\n",
    "3. Réduction dimensionnelle des 100 composantes les plus importantes selon la factorisation NMF.\n",
    "\n",
    "Cette modélisation permet ainsi d'obtenir les résultats suivants sur des données de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb2501f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-samples classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.89      0.83       152\n",
      "        True       0.36      0.18      0.24        50\n",
      "\n",
      "    accuracy                           0.72       202\n",
      "   macro avg       0.56      0.54      0.53       202\n",
      "weighted avg       0.67      0.72      0.68       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "      PredNeg   PredPos\n",
      "Neg  0.673267  0.079208\n",
      "Pos  0.202970  0.044554\n"
     ]
    }
   ],
   "source": [
    "print_pipe_results([X_test, y_test], xgb_lotr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e275072",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Performances\n",
    "\n",
    "Les performances observées ne sont pas très satisfaisantes, mais sont malgré tout à mettre en perspective vis-à-vis de l'objectif visé et des données en entrées.  \n",
    "En effet, comme le démontre le nombre de vrais et faux négatifs et des 72% d'accuracy, le modèle possède une aisance pour traiter les demandes dites illégitimes.  \n",
    "\n",
    "Là où le bât blesse est lorsqu'il s'agit de bien traiter les vrais et faux positifs.  \n",
    "En effet, les 18% de recall entrainent de ce fait l'algorithme à labelliser la plupart des demandes légitimes en tant qu'illégitimes.  \n",
    "\n",
    "Par rapport, à l'objectif business, il est quand même préférable d'avoir cette situation que celle inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad70066",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_donation_pct = round(xgb_lotr_model.predict(X_test_lotr).sum() / len(xgb_lotr_model.predict(X_test_lotr)), 3) * 100\n",
    "real_donation_pct = round(y.sum()/len(y), 3)*100\n",
    "\n",
    "wrapup_concl_prez = f'''Sur les {round(y.sum()/len(y), 3)*100}% de requêtes réelles ayant donné lieu à une donation, le modèle actuel prédit {pred_donation_pct}% de requêtes légitimes devrant donner lieu à une donation.\n",
    "Cela représente une différence de {round(pred_donation_pct/real_donation_pct, 3)*100}%.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e9a41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Les données non textuelles et textuelles travaillent de concert, avec leur poids relatif, pour permettre d'améliorer l'algorithme.  \n",
    "Il serait préjudiciable de se passer d'un des deux types.   \n",
    "Toutefois, les données textuelles sont au cœur de la modélisation.  \n",
    "\n",
    "Après de nombreux essais, xgboost s'est avéré être un bon candidat en le combinant avec une étape de preprocessing pertinente.  \n",
    "Cependant, l'algorithme est relativement strict sur les faux négatifs et conduit à des performances de recall +/- insuffisantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98573e26",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur les 24.6% de requêtes réelles ayant donné lieu à une donation, le modèle actuel prédit 12.4% de requêtes légitimes devrant donner lieu à une donation.\n",
      "Cela représente une différence de 50.4%.\n"
     ]
    }
   ],
   "source": [
    "print(wrapup_concl_prez)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
